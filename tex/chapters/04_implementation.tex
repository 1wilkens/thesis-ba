\chapter{Implementation}
\label{ch:Implementation}

\abstract{This chapter describes the implementation process for all three compared languages. It is divided in sections based on the development milestones defined in the previous chapter~\ref{sec:Approach::Implementation}.
}

\setcounter{section}{-1}
\section{Project setup}
\label{sec:Implementation::Setup}

All applications written for this thesis have been developed on Linux thus the setup instructions are for this operating system. They \textbf{should} work on *nix as well but there is no definite guarantee this is the case. Also each section assumes the toolchains for the various languages are installed as this is largely different based on what operating system and on Linux which distribution is used. It is therefore not covered in this thesis.

\subsection{C}
\label{subsec:Implementation::Setup::C}

//TODO: Add footnotes/links

The buildtool for streets4C is GNU \textit{make} with a simple handcrafted \shinline{Makefile}. It was chosen to strike a balance between full blown build systems like \textit{Autotools} or \textit{CMake} and manual compilation. The setup steps required for this configuration are relatively straight forward and listed below.
\\
\lstinputlisting[caption={Project setup: streets4C}, label={lst:setup_c.sh}, style=shell]{code/setup_c}

After creatig a new directory for the application a \shinline{Makefile} and a sourcefile are created. \shinline{main.c} contains just a bare bones main method while the \shinline{Makefile} uses basic rules to compile an executable named streets4c with various optimization flags.

All in all the setup in C is quite painless although manual. The only caveat are Makefiles. They may be simple for small projects without real dependencies but as soon as different source and object files are involved in the compilation process they can get quite confusing. At that point the mentioned build systems might prove their worth in generating the \shinline{Makefile}(s) from other configuration files.


\subsection{Go}
\label{subsec:Implementation::Setup::Go}

//TODO: Add footnotes/links

For Go the choice of buildtool is nonexistent. The language provides the \shinline{go} executable which is responsible for nearly the complete development cycle. It can compile your code, install arbitrary Go packages from various sources, run tests and format code just to name the most common features.

This makes Go (the language) extremely convenient since everything you want to do is probably one commandline away. For example to get a dependency one would invoke the tool like so:
\mdinline{go get github.com/petar/GoLLRB/llrb}
\\
This will download the package in source form which can then be imported in any project on that machine via its fully qualified package name.

To achieve this convenience the \shinline{go} tool requires some setup work before it can be used for the first time. Because of this this section contains two setup examples.
\\
\lstinputlisting[caption={Project setup: streets4Go}, label={lst:setup_go.sh}, style=shell]{code/setup_go}

Listing \ref{lst:setup_go.sh} describes the steps that were taken to create the streets4go project inside the thesis' repository. It is pretty similiar to the C version. A directory gets creates then a source file containing a \shinline{main} function is created which can be build and run with a single command.

One thing to remind here is the fact, that this code does not live inside a globally set drectory called \shinline{GOPATH}. To be able to download packages only once \shinline{go} assumes an environment variable called \shinline{GOPATH} to be set to a directory which it has full control over. This directory contains all source files as well a the compiled binaries all stored through a consistent naming scheme. Normally it is assumed that all Go project live inside their own subdirectories of the \shinline{GOPATH} but it is possible to avoid this at the cost of some convenience.

The project that was created through the commands of listing \ref{lst:setup_go.sh} for example cannot be installed to the system by running \mdinline{go install} since it does not reside in the correct folder instead one has to copy the compiled binary to a directory in \shinline{PATH} manually.

The next listing shows a more realistic workflow for creating a new Go project from scratch without any prior setup required. It assumes one starts in the directory that should be set as \shinline{GOPATH} and assumes \url{www.github.com} as code host which in reality just determines the package name. It is also important to add the export shown in the first line to any inititalization file of your shell or operating system to ensure it always beeing available.
\\
\lstinputlisting[caption={Full setup for new Go projects}, label={lst:setup_go_full.sh}, style=shell]{code/setup_go_full}


\subsection{Rust}
\label{subsec:Implementation::Setup::Rust}

//TODO: Add footnotes/links

Similar to Go also Rust provides its own build system. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Rust]{candidate introduction} Rust installs its own package manager \textit{cargo}. It functions as build system and is also capable of creating new projects. This shortens the setup process considerably as observable in the next listing.
\\
\lstinputlisting[caption={Project setup: streets4Rust}, label={lst:setup_rust.sh}, style=shell]{code/setup_rust}

With the \shinline{new} subcommand a new project gets created. The \shinline{-{}-bin} flag tells \shinline{cargo} to create an executable project instead of a library which is the default.
Thanks to the one command all the initial files and directories are created with one single command. This includes:
\begin{itemize}
    \item{the project directory itself (named like the given project name)}
    \item{a \shinline{src} directory for source files}
    \item{a \shinline{target} directory for build results}
    \item{a required manifest file named \shinline{Cargo.toml} including the given project name}
    \item{a sample file inside \shinline{src} which is either called \shinline{main.rs} for binaries or \shinline{lib.rs} for libraries containing some sample code
    \item{and optionally an empty initialized version control repository (\shinline{git} or \shinline{mercurial} if the corresponding command line option has been passed)}
\end{itemize}
The resulting application is already runnable via \mdinline{cargo run}\footnote{which is executable anywhere inside the project directory} and produces some output in \shinline{stdout}. This process is extremely convenient and error proof since \shinline{cargo} validates all input before executing any task. The \shinline{man} pages and help texts are quite thin at the moment but as with everything in the Rust world \shinline{cargo} is still beeing developed.

The overall greated advantage however is that the Rust process does not involve any manual text editing. What might sound trivial at first, is actually quite important for newcomers to the language. You do not have to know any syntax to get started with Rust since the generated code already compiles and does something interesting. In the other languages you have to write a valid, minimal program manually to even test the project setup while Rust is ready to go after just one command.

Of course this strategy is not without limitations. To be able to use \shinline{cargo} all files and directories have to follow a special pattern. Although the chosen conventions are somewhat common one cannot use arbitrary directory and file names.


\subsection{Comparison}
\label{subsec:Implementation::Setup::Comparison}

For newcomers Rust definitely provides the best experience. One can get a valid \textit{Hello world!} application without any prior knowledge which lowers the barrier of entry dramatically. In addition Rust does not require any presetup before the first project. just install the language toolchain (either through the operating system's package manager or the very simple setup script~\fnote{\url{https://static.rust-lang.org/rustup.sh}}) and start coding.

Go required some intial setup besides the installation but it still quite easy to setup. The \shinline{GOPATH} exporting is a small annoyance but it balances out with the benefits the developer gets later down the line like easy dependency management. The syntax is very concise so creating a new source file with a \shinline{main} function is still quite fast.

Considering C's long lifespan the tooling for project setup is not very good. Full blown IDEs like Eclipse provide wizards to create all required files but for free standing development with a simple text editor and GNU \textit{make} there is no real automation possible. Naturally it is not hard to create an empty C source file however in this day and age it should not be necessary to manually have to adjust the order of linker flags in the \shinline{Makefile} because of obscure warnings in the compilation process.

This probably does not apply to seasoned C developers and one could make the argument that it is inherent to the language's ``closeness to the metal''. But acknowledging the fact that scientists more often than not see programming as an unwanted necessity to be able to complete their research it is questionable whether this technical know-how should really be required to use a language like C.

//TODO: maybe to wordy?

\section{Counting nodes, ways and relations in an .osm.pbf file}
\label{sec:Implementation::Counting}

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        SLOC
            & 163
            & 55
            & 36 \\

        Development time (hours)
            & 00:51:18
            & 00:21:16
            & 00:33:09 \\

        Execution time (sec)
            & 1.017 (-O0)
            & 4.846 (GOMAXPROCS=1)
            & 27.749 (-O0) \\
            & 0.994 (-O3)
            & 1.381 (GOMAXPROCS=8)
            & \hspace{6pt}2,722 (-O3) \\

        Allocation count
            & 2,390,566
            & 11,164,068\fnote{The memory statistics for Go have not been acquired by valgrind but by \shinline{runtime.MemStats} this and the fact that Go is garbage collected explain the discrepancy in allocations and frees}
            & 11,373,558 \\

        Free count
            & 2,390,566
            & 11,000,199\fnote{See footnote 3 //todo: verify footnote nr in final draft}
            & 11,373,557\fnote{This is due to a bug in the osmpbf library used. In safe Rust code it is very hard to leak memory (usually involving reference cycles or something similar).} \\
        \bottomrule
    \end{tabular}
    \caption{Milestone 1: Counting nodes, ways and relations}
    \label{tb:milestone1}
\end{table}

\subsection{C}
\label{subsec:Implementation::Counting::C}

Preface: For the first real milestone \textit{streets4C} had an important disadvantage. There was no library to conveniently process OpenStreetMap data. Therefore a small abstraction over the offical Protobuf definitions had to be written. The development time for this code located in \shinline{osmpbfreader.c/h} was not counted towards the total time of the phase to avoid unfair bias just because of a missing library however the \gls{sloc} count includes the additional code since it was essential to this stage.

The first phase of development already highlighted many of the common problems encountered when programming in the C language. After finishing the aforementioned library it had to be invluded in the development process which in return meant the \shinline{Makefile} had to be extended to also compile \shinline{osmpbfreader.c} and include the resulting object file in assembling the executable binary. This proved harder than expected which can partly be attributed to my lacking expertise with the C compilation process but also confirms the unneeded complexity of such a simple task. In the end the problem was the order in which the sorce files and libraries where passed to the compiler. The libraries were included too early which resulted in ``undefined reference to method'' error messages. In times where compilers are smart enough to basically rewrite and change code for performance reasons it is completely inexcusable that the order of source arguments to process is still that relevant. The time spent solving these complication errors shows in the statistics for C which is considerably larger than its competitors in this stage.

The other big caveat in working with \gls{osm} data was the manual memory management. Since said data is stored in effectively compressed manner in the file additional heap allocations were unavoidable in accessing it. This requires either explicit freeing by the caller or a symmetric deallocation function provided by the library. In the case of Protobuf it is even worse since a client cannot just perform the usual \mdinline{free(..)} call but has to use the custom free functions generated from the source \shinline{.proto} format description files. For some intermediate allocations it is possible to limit this to the body of a libaray function but on the real data it shifts additional responsibilities on the caller.
\\
\lstinputlisting[caption={Manual memory management with Protobuf in C}, label={lst:manual_pbf_freeing.c}, style=c]{code/manual_pbf_freeing.c}

Considering this fact the \gls{sloc} count is still decent. With the help of a clever library interface the overhead for the memory management is comparatively small and the data is even loopable by a \shinline{while} loop which allows for convenient access and conversion. Also the statistics clearly show why C is still that dominant in the \gls{hpc} area. With low allocation counts~\fnote{Although these are also caused by the simplicity of the custom osmpbfreader abstraction} and superior singlethreaded(!) performance C is the clear winner in the performance area for this first milestone.

\subsection{Go}
\label{subsec:Implementation::Counting::Go}

To parse the .osm.pbf files \textit{streets4Go} uses an existing library simply called \shinline{osmpbf}~\fnote{\url{https://github.com/qedus/osmpbf}}. The library follows common Go ``best practices'' which makes it easy to use. Internally goroutines are used to decode data in parallel which can then be retrieved through a \shinline{Decoder} struct. The naming of the struct and the corresponding methods follow the conventions of the official Decoder types of the Go standard library. This adherence to conventions directly shows in the development time which is the shortes amongst the candidates for this first phase.
\\
\lstinputlisting[caption={Dependency management in Go}, label={lst:dependency_management.go}, style=go]{code/dependency_management.go}

Dependency management was very easy and intuitive. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Go]{candidate introduction} \mdinline{go get} was used to download the library and a simple import statement was enough to pull in the necessary code (see \autoref{lst:dependency_management.go}). One caveat here is once again Go stricts compilation rules. Since an unused import is a compiler error an/my (//wording?) editor plugin kept deleting the prematurely inserted import statement as part of the saving process. While the auto fix style of tools like \shinline{gofmt} and \shinline{goimports} is certainly helpful for fixing common formatting errors, the loss of control for the developer takes some time to get used to. (//really include that?)

Another interesting recorded statistic is the count of \acrlong{sloc}. This count exposes one of the criticisms commonly directed at Go - verbose error handling. Although the code is semantically simpler (no manual memory management, higher level language constructs) the \gls{sloc} count is in fact identical to that of \textit{streets4C}. This is the result of the common four line idiom to handle errors. A function that could fail typically returns two values. The desired result and an error value. If the function failed to execute successfully the error value will indicate the source of the failed execution. Otherwise this value will be \shinline{nil} signalling a failure free completion. This pattern is used three times in this simple first phase alone which results in 12 lines.
\\
\lstinputlisting[caption={Idiomatic error handling in Go}, label={lst:error_handling.go}, style=go]{code/error_handling.go}

Considering the aforementioned simplicity \textit{streets4Go}'s performance characteristics are very promising. Although in its basic form about four to five times slower than the C solution the parallelized version achieves similar performance. This version was only included since the library was already based on a variable number of \glspl{goroutine} which made the parallelzation a matter of changing an environment variable in the Go runtime. While this change required only the addition of a single line, the C abstraction \shinline{osmpbfreader} might not even be parallelizable without considerable changes to its architecture. This truly shows the power of language level parallelization mechanics and confirms the choice of Go as a candidate in this evaluation.

\subsection{Rust}
\label{subsec:Implementation::Counting::Rust}

\textit{streets4Rust} also had the advantage of an existing library to use for \gls{osm} decoding which is called \textit{osmpbfreader-rs}~\fnote{\url{https://github.com/texitoi/osmpbfreader-rs}}. Similar to Go the dependency management was extremely convenient and simple. The only changes necessary were an added line in the Cargo manifest (Cargo.toml) and an \shinline{extern crate osmpbfreader;} in the crate root \shinline{main.rs}. After that \mdinline{cargo build} downloaded the dependency (which in this case meant cloning the \shinine{git} repository) and integrated it into the compilation process.

Compared to C and Go \textit{streets4Rust} required a medium amount of development time and had the lowest \gls{sloc} count in this phase. This can mainly be attributed to the library's use of common Rust idioms and structures like \shinline{iterators} and \shinline{enums}. Unlike C enums, which are basically named integer constants, the Rust variant provides a lot more features like beeing useable in pattern matching expressions. The next listing shows the complete decode part of this stage which is very compact and easy to understand.  //add implementation details of the lib? (chained interators)
\\
\lstinputlisting[caption={\gls{osm} decoding in Rust}, label={lst:osm_decoding.rs}, style=rust]{code/osm_decoding.rs}

The function \mdinline{blocks::iter} returns an enum value which gets pattern matched on to determine which counter should get incremented. While this example does not actually use any fields of the objects it would be a simple change to destructure the enum values and retrieve the structures containing the data.

The execution time highlights another important factor in regards to Rust's matureness as a language. The optimized version is more than ten times faster then the binary produced by default options. This is mostly due to the fact that the Rust \gls{llvm} frontend produces bloated byte code which does not get optimized on regular builds. That is also the reason release builds take substanstially longer. It simply takes more time to optimize (and therefore often shrink) \gls{llvm_ir} instead of emitting less code in the first place. Although the code generation gets improved steadily it is not a big focus until version \shinline{1.0} is released but the Rust core team knows about the issue and it is a high priority after said release.

Nonetheless the release build shows the power of \gls{llvm}'s various optimization passes. \textit{streets4Rust} achieves the second best single threaded performance after C with a run time of 2.72 seconds which is impressive considering the vastly shorter development time and lowest \gls{sloc} count across all candidates.

\subsection{Comparison}
\label{subsec:Implementation::Counting::Comparison}

\section{Building a basic graph representation}
\label{sec:Implementation::Graph_Representation}

The second milestone was to develop a graph structure to represent the street network in memory. Like in \textit{streets4MPI} random nodes from this data would then be fed to Dijkstra's shortest path algorithm to simulate trips. Since all applications should be parallelized later on the immutable data (such as the edge lengths, \gls{osm} IDs and adjecency lists) needed to be stored separately from the changing data the algorithm required (such as distance and parent arrays). To achieve this all implementations have a \shinline{graph} structure holding the immutable data and a \shinline{dijkstragraph} structure to store volatile data for the algorithm alongside some kind of reference (or pointer) to a graph object.

Since this milestone included a preliminary implementation of the actual algorithm it required the use of a priority queue which was not directly available in all languages. Considering this fact the third milestone already highlighted some differences in comprehensiveness of the different standard libraries.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        SLOC (total)
            & 385
            & 196
            & 170 \\

        Development time (hours)
            & 02:30:32
            & 01:06:06
            & 01:14:28 \\
        \bottomrule
    \end{tabular}
    \caption{Milestone 2: Building a basic graph representation}
    \label{tb:milestone2}
\end{table}

\subsection{C}
\label{subsec:Implementation::Graph_Representation::C}
// TODO: shorten this? other sections are shorter

As seen in \autoref{tb:milestone2} this stage resulted in a much higher \gls{sloc} count for C. This is due to the fact that development took place in another source files. To encapsulate graph functionality properly a new file called \shinline{graph.c} was created. Following established conventions this meant also creating a matching header (\shinline{graph.h}) to be able to use the newly written code in the main application. While this separation is decently useful to not have to clobber you source file with structure definitions it also introduces a fair bit of redundancy. Functions are declared in the header and implemented in the source files which means the signature appears twice. In addition C had the unfortunate problem of not having a proper implementation of a priority queue easily available which required the addition of another source file / header combination (\shinline{util.c/h}). This increased the \gls{sloc} count even further and added some additional development time as well.

At this point it became clear the C version would not be created dependency free. Advanced data structures such as hash tables or growing arrays are essential when properly modelling a graph and the choice was made to use the popular \textit{GLib}~\fnote{\url{https://developer.gnome.org/glib/stable/}} to provide these types. It is a commonly used library containing data structures, threading routines, conversion functions or macros and much more. Since both Rust and Go's standard library are mch more comprehensive then C's the addition of GLib to the project is easily justified.

Implementing the graph representation itself was very straight forward. Similar to the mathematical representation a \shinline{graph} in \textit{streets4C} consists of an array of \shinline{node}s and \shinline{edge}s. To be able to map from \gls{osm} IDs to array indices two hash tables were added using \lstinline[style=c]{long}s as keys and \lstinline[style=c]{int}s as values. The \shinline{dgraph} structure can be created with a pointer to an existing \shinline{graph} and is then able to execute Dijkstra's \acrshort{sssp} algorithm.
\\
\lstinputlisting[caption={Graph representation in C}, label={lst:graph_representation.c}, style=c]{code/graph_representation.c}

All structures contain little more than the expected data bseides the \shinline{cur} field in \shinline{dgraph}. It needed to be added since Glib's \shinline{GHashTable} only support operations on all key-value-pairs via a function pointer with a single extra argument. Since the algorithm at on particular required access to the currently explored node's index as well as the distance and parent arrays the index needed to be stored in the struct itself.

While the additional field was a minor inconvenience other problematic aspects were the code bloat and added unsafety intrduced by the use of \shinline{GHashTable}s\fnote{The hash table implementation provided by GLib}. Since C is not typesafe by design and does not allow for true generic programming via type parameters nearly all generic code is written using \lstinline[style=c]{void*}. This leads to very verbose code because of the high amount of casts involved when accessing or storing values inside the data structures mentioned earlier.

Another complication was the use of integers as keys in \shinline{GHashTable}. It requires both key an value to be a gpointer (which is a platform independant \lstinline{void} pointer) which forces the programmer to either allocate the integer key on the heap or explicitly cast it to the correct type. This works well using a macro provided by GLib until the number zero appears as a value because it represent the \shinline{NULL} pointer which GHashTable also uses to indicate a key was not found in the hash table.

The implementation of Dijkstra's algorithm was not particularly hard only more verbose than expected. As mentioned the GHashTable only provides iterative access through an extra function. As a consequence the step commonly referred to as \textit{relax edge} is contained in a separate function that get passed to \shinline{g\_hash\_table\_foreach}. In combination with the conversion macros and temporary variables the code bloats up.

All in all the experience was poor compared to the other languages. The verboseness and missing safety lead to the highest development time and \gls{sloc} count by far. The time was spent debugging some obscure errors introduced by the excessive casting which might have been avoided by a more sophisticated typesystem.

\subsection{Go}
\label{subsec:Implementation::Graph_Representation::Go}

For Go a similar approach was chosen. The graph is again mostly composed of two arrays holding all nodes and edges. However unlike the native C variants Go's \shinline{slices} and \shinline{maps} are dynamically growing which means the constructor function of the graph does not require capacity parameters. In general the development process was once again very smooth and simple which shows in the short time spent and the low \gls{sloc} count.
\\
\lstinputlisting[caption={Graph representation in Go}, label={lst:graph_representation.go}, style=go]{code/graph_representation.go}

As the listing shows the structures are nearly identical to their C counterparts. Only the current node index in DijkstraGraph was not required since Go allows for much better iteration through maps. It is also interesting to note that Go supports (and even encourages) the declaration of multiple fields of the same type on the same line. Although this was used only two times in the snippet it shrinks the line count while keeping the code understandable since two fields with identical types are often related anyway.

As stated in the introductory part Dijkstra's algorithm depedends on a priority queue. Despite the fact that Go's standard library does not directly provide a ready-to-use implementation thereof the required steps to achieve this were minimal. The package \shinline{container\textbackslash heap}\fnote{\url{http://golang.org/pkg/container/heap/}} offers a convenient way to work with any kind of heap. The only restriction is that the underlying data structure implements a special interface containing common operations used to \textit{heapify} the stored data. Since interfaces are implicitly implemented on all structures which present the necessary methods it was a simple task to create a full featured priority queue on top of a slice by writing just four trivial methods.
\\
\lstinputlisting[caption={Priority queue in Go}, label={lst:priority_queue.go}, style=go]{code/priority_queue.go}

While the heap implementation was provided by the standard library (which is likely to be correct) it required the custom methods of \autoref{lst:priority_queue.go} to be correct. At this point Go's builtin test functionality came in handy. All it took to test the custom implementation was to create another file called \shinline{util\_test.go} (adding the suffix ``\_test'' to the already existing file \shinline{util.go}) and write a simple test. No import besides the \textit{testing} package were needed since the code resided in the same package as the main application and all test got executed with a single call of \mdinline{go test} from the commandline. In contrast the C implementation of the queue required the setup of an additional source file including a regular main function which then had to manually compiled and run. In addition some basic error formatting and output\fnote{Which potentially could also contain errors(!)} had to be written to properly locate potential errors in the implementation. Although all test related statistics are not counted in either language, Go's testing workflow is clearly superior to the manual, errorprone C approach.

All things considered this milestone was easily implemented in Go. The builtin container datastructures simplified the structure definitions while the provided heap implementation had a very low entry barrier and produced quick results. This reflect in the statistics which are on par with the Rust version discussed in the next section. \\technically a subsection?

\subsection{Rust}
\label{subsec:Implementation::Graph_Representation::Rust}

The original plan for the Rust implementation was to use direct references between nodes and edges of the graph to allow for easy navigation during the algorithm. Combined with the guarantees the typesystem offers it seemed to be a unique approach offering both convenient access and memory safety. Unfortunately this approach was quickly dismissed since it would have essentially created circular datastructures. While those are definitely possible to implement, it takes some \shinline{unsafe} marked code and a lot of careful interface design to retain the aforementioned safety. Due to once again time restrictions a architecture to the Go and C variant was implemented

The interesting differences in contrast to the previously introduced structures are located in \shinline{DijkstraGraph}. The \shinline{queue} field has the type \shinline{BinaryHeap} which is located in the standard library. This already shows that Rust is the only language out of the candidates which contains a complete implementation of this datastructure as part of the core libraries. While a priority queue is certainly not an essential component of every program it was required for this algorithm and having it available right from the start was beneficial to the development.
\\
\lstinputlisting[caption={DijkstraGraph in Rust}, label={lst:graph_representation.rs}, firstline=24, style=rust]{code/graph_representation.rs}

The other interesting part is the type of the \shinline{graph} field. As mentioned earlier the struct calculating the shortest paths needs a reference to the immutable graph data. Ideally one would like to encode this immutability in the type itself. This is where Rust's typesystem shines. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Rust]{language introduction} regular references only allow read access. This means DijkstraGraph cannot (accidentally or intentionally) modify the referenced Graph instance or any of its fields just because the reference does not allow this. This comes in handy later in a parallel scenario where multiple threads are reading data from the graph while calculating shortest paths. The readonly reference (in Rust terms ``a shared borrow'') ensures no data races can happen when accessing the graph concurrently.

From a statistics standpoint Rust is evenly matched with Go. While \textit{streets4Go} took a little less time to write, \textit{streets4Rust} has a few less lines. This mostly came down to the heap implementations being available in the standard library (which means less code had to be written) and the mentioned deviation from the original implementation plan, adding some additional development time.

\subsection{Comparison}
\label{subsec:Implementation::Graph_Representation::Comparison}

Although this milestone did not contain any performance measurements it clearly highlighted and emphasized the original argument for a new language in \acrlong{hpc}. In scenarios where complex data structures beyond a simple array are required C fails to deliver an easy development experience. This was mostly due to the lack of ``true'' generic programming limiting the expressiveness of the implemented structures and algorithms. Since all casts in C are unsafe anyway but required to enable genericity, one slight type error, which a rigid typesystem might have been prevented from even compiling, can cause segmentation faults which are hard to trace and correct. This clearly underlines that C is not the optimal choice for developing complex high performance applications.

Go and Rust performed equally well in this stage. Both include a typesystem suited to safely use generic containers and provide a sufficient standard library for a decent implementation of a shortest path algorithm. Although Go's generics are limited to builtin types like slices and maps this was not an issue in this stage since no generic methods had to be written. Rust had the unique advantage to be able to express application semantics (graph data is immutable to the algorithm) in the typesystem. Although that did not solve any immediate problems in the implementation it can help to prevent a whole class of defects as described in the previous section.

\section{Verifying structure and algorithm}
\label{sec:Implementation::Verification}

The next goal was to verify the implemented algorithms on some sample data. To achieve this a sample graph with ten nodes and about 15 edges was constructed followed by a shortest path calculation for each node. Although performance was measured it was not the core focus of this stage since the input data was very small and not representative of the \gls{osm} data. Nonetheless the execution time reveals some interesting differences between the competitors.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        SLOC (total)
            & 637
            & 268
            & 232 \\

        Development time (hours)
            & 01:53:30
            & 01:16:49
            & 01:04:38 \\

        Execution time (seconds)
            & 0.004 (-O0)
            & 0.296
            & 0.007 (-O0) \\
            & 0.003 (-O3)
            & % itentionally blank since no parallel version was build
            & 0.005 (-O3) \\

        Allocation count
            & 108
            & 519\fnote{See footnote 3}
            &  47 \\

        Free count
            & 106\fnote{Due to the use of GLib some global state remains reachable after exiting. This is likely intended behaviour and not a memory leak (see: \url{http://stackoverflow.com/a/4256967}).}
            & 169\fnote{See footnote 3}
            &  47 \\

        Allocation amount (bytes)
            & 7,868\fnote{2,036 bytes were in use at exit see footnote 14}
            & 53,016
            & 22,792
        \bottomrule
    \end{tabular}
    \caption{Milestone 3: Verifying the implementation}
    \label{tb:milestone3}
\end{table}

\subsection{C}
\label{subsec:Implementation::Verification::C}

Unsurprisingly the C implementation has the lowest execution time among the compared languages. Unfortunately the performance was once again paid with a high development time following the trend from previous milestones.

\subsection{Go}
\label{subsec:Implementation::Verification::Go}


\subsection{Rust}
\label{subsec:Implementation::Verification::Rust}


\subsection{Comparison}
\label{subsec:Implementation::Verification::Comparison}


\section{Sequential benchmark}
\label{sec:Implementation::SequentialBenchmark}

In this milestone runtime performance came back into focus. Since the algorithms at this point were proven to work correctly it could now be applied to real geographical data. The main technical challenge here was to efficiently process the input file while ideally directly filling the graph with the accumulated data. The caveat was the handling of \gls{osm} \shinline{ways} which are later represented by one or more edges in the graph. The input format lists all ids of the nodes which are part of the way but these nodes might not have been processed and added to the graph yet. This forced the implementations to retain the ways' data in some way and construct edges from that data in a second step.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        SLOC (total)
            & 757
            & 359
            & 292 \\

        Development time (hours)
            & 01:14:32
            & 00:56:16
            & 00:45:20 \\

        Execution time (hours)
            & 08:34:01 (-O3)
            & 09:08:19
            & 07:31:37 (-O3) \\

        Memory usage (MB)~\fnote{Obtained via htop (\url{http://hisham.hm/htop/}) at the time of shortest path calculation}
            & 994
            & 1551
            & 2235 \\

        \bottomrule
    \end{tabular}
    \caption{Milestone 4: Sequential benchmark}
    \label{tb:milestone4}
\end{table}

\subsection{C}
\label{subsec:Implementation::SequentialBenchmark::C}

For \textit{streets4C} the most time was spent on dealing with the edges. As mentioned in the introductory part they need to be saved and added later. This either required knowing the amount of edges beforehand (to be able to preallocate an array large enough to store all information) or to use a dynamically growing array to store them as they get processed. Since the amount of edges is not stored in the \gls{osm} file, the first approach would have to read the whole input file twice to count edges (and ideally nodes too) first and then parse the actual data in the second run. To prevent this the second design as implemented.

Of course reallocating arrays are not part of the C language or standard library and the application had to rely on GLib once again. The used types were \shinline{GPtrArray} to store pointers to the heap allocated \textit{node} and \textit{edge} structures and the regular \shinline{GArray} to store the \gls{osm} ids of the constructed edges. With this implementation the file only needed to get read once creating the actual values and counts (useful to pass to the graph creation method as capacities later) in the process.

Another option would have been to rewrite part of the graph structure to use GArrays internally for storing edges and nodes in the first place. This idea was not realized to keep the number of external datastructures in the graph reresentation minimal. However that change would have simplified this milestone considerably.


\subsection{Go}
\label{subsec:Implementation::SequentialBenchmark::Go}


\subsection{Rust}
\label{subsec:Implementation::SequentialBenchmark::Rust}


\subsection{Comparison}
\label{subsec:Implementation::SequentialBenchmark::Comparison}



\section{Parallel benchmark}
\label{sec:Implementation::ParallelBenchmark}

Last but not least it was time to parallelize the calculations.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        SLOC (added)
            & 777
            & 381
            & 314 \\

        SLOC (final)
            &
            &
            & \\

        Development time (hours)
            & 00:08:11
            & 00:07:56
            & 00:27:23 \\

        Execution time (4 threads) (hours)
            & 03:22:21 (-O3)
            & 03:47:30
            & 02:32:06 (-O3) \\

        Memory usage (MB)~\fnote{Obtained via htop (\url{http://hisham.hm/htop/}) at the time of shortest path calculation}
            & 994
            & 1551
            & 2235 \\

        \bottomrule
    \end{tabular}
    \caption{Milestone 5: Parallel benchmark}
    \label{tb:milestone5}
\end{table}

\subsection{C}
\label{subsec:Implementation::ParallelBenchmark::C}


\subsection{Go}
\label{subsec:Implementation::ParallelBenchmark::Go}


\subsection{Rust}
\label{subsec:Implementation::ParallelBenchmark::Rust}


\subsection{Comparison}
\label{subsec:Implementation::ParallelBenchmark::Comparison}
