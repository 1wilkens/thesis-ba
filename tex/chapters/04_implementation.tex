\chapter{Implementation}
\label{ch:Implementation}

\abstract{This chapter describes the implementation process for all three compared languages. It is divided in sections based on the development milestones defined in the previous chapter~\ref{sec:Approach::Implementation}.
}

\setcounter{section}{-1}
\section{Project setup}
\label{sec:Implementation::Setup}

All applications written for this thesis have been developed on Linux thus the setup instructions are for this operating system. They \textit{should} work on *nix as well but there is no guarantee this is the case. Also each section assumes the toolchains for the various languages are installed as this is largely different based on what operating system and on which Linux distribution is used. It is therefore not covered in this thesis.

\subsection{C}
\label{subsec:Implementation::Setup::C}

The buildtool for \textit{streets4C} is GNU \textit{make} with a simple handcrafted \mdinline{Makefile}. It was chosen to strike a balance between full blown build systems like \textit{Autotools}\fnote{\url{http://www.gnu.org/software/software.html}} or \textit{CMake}\fnote{\url{http://www.cmake.org}} and manual compilation. The setup steps required for this configuration are relatively straight forward and listed below.
\\
\lstinputlisting[caption={Project setup: streets4C}, label={lst:setup_c.sh}, style=shell]{code/setup_c}

After creatig a new directory for the application a \mdinline{Makefile} and a sourcefile are created. \mdinline{main.c} contains just a bare bones main method while the \mdinline{Makefile} uses basic rules to compile an executable named \textit{streets4c} with various optimization flags.

All in all the setup in C is quite painless although manual. The only caveat are \mdinline{Makefile}s. They may be simple for small projects without real dependencies but as soon as different source and object files are involved in the compilation process they can get quite confusing. At that point the mentioned build systems might prove their worth in generating the \mdinline{Makefile}(s) from other configuration files.

\subsection{Go}
\label{subsec:Implementation::Setup::Go}

For Go the choice of buildtool is nonexistent. The language provides the \shinline{go} executable which is responsible for nearly the complete development cycle. It can compile your code, install arbitrary Go packages from various sources, run tests and format code just to name the most common features.

This makes Go (the language) extremely convenient since everything you want to do is probably one commandline away. For example to get a dependency one would invoke the tool like so: \mdinline{go get github.com/petar/GoLLRB/llrb}. This will download the package in source form which can then be imported in any project on that machine via its fully qualified package name.

To achieve this convenience the \shinline{go} tool requires some setup work before it can be used for the first time. Because of this this section contains two setup examples.
\\
\lstinputlisting[caption={Project setup: streets4Go}, label={lst:setup_go.sh}, style=shell]{code/setup_go}

Listing \ref{lst:setup_go.sh} describes the steps that were taken to create the \textit{streets4Go} project inside the thesis's repository. It is pretty similiar to the C version. A directory gets created then a source file containing a \shinline{main} function is created which can be built and run with a single command. Unfortunately this variant does not follow the guidelines for project layout as described in \href{https://golang.org/doc/code.html#Workspaces}{the official documentation} because the code does not live inside the globally unique \shinline{GOPATH} folder.

To be able to download packages only once the \shinline{go} commandline utility assumes an environment variable called \shinline{GOPATH} is configured to point to a directory which it has full control over. This directory contains all source files as well a the compiled binaries all stored through a consistent naming scheme. Normally it is assumed that all Go projects live inside their own subdirectories of the \shinline{GOPATH} but it is possible to avoid this at the cost of some convenience.

The project that was created through the commands of \autoref{lst:setup_go.sh} for example cannot be installed to the system by running \mdinline{go install} since it does not reside in the correct folder instead one has to copy the compiled binary to a directory in \shinline{PATH} manually.

The next \hyperref[lst:setup_go_full.sh]{Listing} shows a more realistic workflow for creating a new Go project from scratch without any prior setup required. It expects the programmer to start in the directory that should be set as \shinline{GOPATH} and uses \href{https://www.github.com}{\shinline{GitHub}} as code host which in reality just determines the package name. It is also important to add the export shown in the first line to any inititalization file of your shell or operating system to ensure it is accessible everywhere.
\\
\lstinputlisting[caption={Full setup for new Go projects}, label={lst:setup_go_full.sh}, style=shell]{code/setup_go_full}

\subsection{Rust}
\label{subsec:Implementation::Setup::Rust}

Similar to Go also Rust provides its own build system. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Rust]{candidate introduction} Rust installs its own package manager \textit{cargo}. It functions as build system and is also capable of creating new projects. This shortens the setup process considerably as observable in the next \hyperref[lst:setup_rust.sh]{Listing}.
\\
\lstinputlisting[caption={Project setup: streets4Rust}, label={lst:setup_rust.sh}, style=shell]{code/setup_rust}

With the \shinline{new} subcommand a new project gets created. The \shinline{-{}-bin} flag tells \shinline{cargo} to create an executable project instead of a library which is the default.
Thanks to the one command all the initial files and directories are created with one single command. This includes:
\begin{itemize}
    \item{the project directory itself (named like the given project name)}
    \item{a \mdinline{src} directory for source files}
    \item{a \mdinline{target} directory for build results}
    \item{a required manifest file named \mdinline{Cargo.toml} including the given project name}
    \item{a sample file inside \mdinline{src} which is either called \mdinline{main.rs} for binaries or \mdinline{lib.rs} for libraries containing some sample code
    \item{and optionally an empty initialized version control repository (\shinline{git} or \shinline{mercurial} if the corresponding command line option has been passed)}
\end{itemize}
The resulting application is already runnable via \shinline{cargo run}\footnote{Which is executable anywhere inside the project directory} and produces some output in \shinline{stdout}. This process is extremely convenient and error proof since \shinline{cargo} validates all input before executing any task. The \shinline{man} pages and help texts are quite thin at the moment but as with everything in the Rust world \shinline{cargo} is still in active development.

The overall greatest advantage however is that the Rust process does not involve any manual text editing. What might sound trivial at first, is actually quite important for newcomers to the language. You do not have to know any syntax to get started with Rust since the generated code already compiles and does something interesting. In the other languages you have to write a valid, minimal program manually to even test the project setup while Rust is ready to go after just one command.

Of course this strategy is not without limitations. To be able to use \shinline{cargo} all files and directories have to follow a special pattern. Although the chosen conventions are somewhat common one cannot use arbitrary directory and file names.

\subsection{Comparison}
\label{subsec:Implementation::Setup::Comparison}

For newcomers Rust definitely provides the best experience. One can get a valid \textit{Hello world!} application up and running without any prior knowledge which lowers the barrier of entry dramatically. In addition Rust does not require any presetup before the first project. Just install the language toolchain (either through the operating system's package manager or the very simple setup script\fnote{\url{https://static.rust-lang.org/rustup.sh}}) and start coding.

Go requires some intial setup besides the installation but is still quite easy to setup. The \shinline{GOPATH} exporting is a small annoyance but it balances out with the benefits the developer gets later down the line like easy dependency management. The syntax is very concise so creating a new source file with a \shinline{main} function is still quite fast.

Considering C's long lifespan the tooling for project setup is not very good. Full blown IDEs like Eclipse provide wizards to create all required files but for free standing development with a simple text editor and GNU \textit{make} there is no real automation possible. Naturally it is not hard to create an empty C source file however the compiler and linker usability is still years behind other modern toolchains. One example is linking libraries where the developer can decide between potentially unneeded libraries being included in the application (with default settings) or having to carefully order the linker arguments (with the special flag \shinline{-{}-as-{}-needed}) which is tedious when new dependencies get added later on.

This probably does not apply to seasoned C developers and one could make the argument that it is inherent to the language's ``closeness to the metal''. But acknowledging the fact that scientists of other fields more often than not see programming as an unwanted necessity to be able to complete their research it is questionable whether this technical know-how should really be required to use a language like C.

\section{Counting nodes, ways and relations in an .osm.pbf file}
\label{sec:Implementation::Counting}

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        \gls{sloc}
            & 163
            & 55
            & 36 \\

        Development time (hours)
            & 00:51:18
            & 00:21:16
            & 00:33:09 \\

        Execution time (sec)
            & 1.017 (-O0)
            & 4.846 (GOMAXPROCS=1)
            & 27.749 (-O0) \\
            & 0.994 (-O3)
            & 1.381 (GOMAXPROCS=8)
            & \hspace{6pt}2,722 (-O3) \\

        Allocation count
            & 2,390,566
            & 11,164,068\fnote{The memory statistics for Go have not been acquired by \textit{valgrind} but by \shinline{runtime.MemStats}}\textsuperscript{,}\fnote{The fact that Go is garbage collected explains the discrepancy in allocations and frees}
            & 11,373,558 \\

        Free count
            & 2,390,566
            & 11,000,199
            & 11,373,557\fnote{This is due to a bug in the osmpbf library used. In safe Rust code it is very hard to leak memory (usually involving reference cycles or something similar).} \\
        \bottomrule
    \end{tabular}
    \caption{Milestone 1: Counting nodes, ways and relations}
    \label{tb:milestone1}
\end{table}

\subsection{C}
\label{subsec:Implementation::Counting::C}

Preface: For the first real milestone \textit{streets4C} had an important disadvantage. There was no library to conveniently process \gls{osm} data. Therefore a small abstraction over the offical \gls{protobuf} definitions had to be written. The development time for this code located in \mdinline{osmpbfreader.c/h} was not counted towards the total time of the phase to avoid unfair bias just because of a missing library however the \gls{sloc} count includes the additional code since it was essential to this stage.

The first phase of development already highlighted many of the common problems encountered when programming in the C language. After finishing the aforementioned library it had to be included in the development process which in return meant the \mdinline{Makefile} had to be extended to also compile \mdinline{osmpbfreader.c} and include the resulting object file in assembling the executable binary. This proved harder than expected which can partly be attributed to the author's lacking expertise with the C compilation process but also confirms the unneeded complexity of such a simple task.

Ultimately the problem was the order in which the source files and libraries were passed to the compiler and linker. The libraries were included too early which resulted in ``undefined reference to method'' error messages because the aforementioned linker flag \shinline{-{}-as-{}-needed} was enabled per default by the Linux distribution. In this mode the linker effectively treats passed objects files as completed when no missing symbols are found after the unit has been processed and therefore ignores them in the further linking process. As a result the arguments have to carefully match the dependency hierarchy to not accidentally remove a critical library early on so that later files cannot use their symbols.

In times where compilers are smart enough to basically rewrite and change code for performance reasons it is completely inexcusable that the order of source arguments to process is still that relevant. Meanwhile other toolchains show that it is definitely possible to accept arguments in arbitrary order and perform the required analysis whether to include a given library in a second pass. This effectively combines the best of both inferior strategies the C linker currently supports. The time spent solving these compilation errors shows in the statistics for C which is considerably larger than its competitors in this stage.

The other big caveat in working with \gls{osm} data was the manual memory management. Since said data is stored in effectively compressed manner in the file additional heap allocations were unavoidable in accessing it. This requires either explicit freeing by the caller or a symmetric deallocation function provided by the library. In the case of \gls{protobuf} it is even worse since a client cannot just perform the usual \shinline{free()} call but has to use the custom freeing functions generated from the source \shinline{.proto} format description files. For some intermediate allocations it is possible to limit this to the body of a libaray function but on the real data it shifts additional responsibilities on the caller.
\\
\lstinputlisting[caption={Manual memory management with Protobuf in C}, label={lst:manual_pbf_freeing.c}, style=c]{code/manual_pbf_freeing.c}

\autoref{lst:manual_pbf_freeing.c} shows this overhead introduced by the mandatory call to \shinline{osmpbf\_\_primitive\_block\_\_free\_unpacked} in line 17. This results in some very asymmetric interface design since the parsing library has to rely on the client application to explicitly call the correct free function from the \gls{protobuf} library. While this approach is acceptable for regular allocations via the C standard library, it is a problem here since the allocating function's name \shinline{get\_next\_primitive} does not directly imply a heap allocation (and the resulting need to free it later).

Considering this fact the \gls{sloc} count is still decent. With the help of a clever library interface the overhead for the memory management is comparatively small and the data is even loopable by a \shinline{while} loop which allows for convenient access and conversion. Also the statistics clearly show why C is still that dominant in the \gls{hpc} area. With low allocation counts\fnote{Although these are also partially caused by the simplicity of the custom osmpbfreader abstraction} and superior singlethreaded(!) performance C is the clear winner in the performance area for this first milestone.

\subsection{Go}
\label{subsec:Implementation::Counting::Go}

To parse the .osm.pbf files \textit{streets4Go} uses an existing library simply called \textit{osmpbf}\fnote{\url{https://github.com/qedus/osmpbf}}. The library follows common Go ``best practices'' which makes it easy to use. Internally goroutines are used to decode data in parallel which can then be retrieved through a \shinline{Decoder} struct. The naming of the struct and the corresponding methods follow the conventions of the official Decoder types of the Go standard library. This adherence to conventions directly shows in the development time which is the shortest amongst the candidates for this first phase.
\lstinputlisting[caption={Dependency management in Go}, label={lst:dependency_management.go}, style=go]{code/dependency_management.go}

Dependency management was very easy and intuitive. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Go]{candidate introduction} \mdinline{go get} was used to download the library and a simple import statement was enough to pull in the necessary code (see \autoref{lst:dependency_management.go}). One caveat here are once again Go's strict compilation rules. Since an unused import is a compiler error an editor plugin kept deleting the prematurely inserted import statement as part of the saving process. While the auto fix style of tools like \shinline{gofmt} and \shinline{goimports} is certainly helpful for fixing common formatting errors, the loss of control for the developer takes some time to get used to.

Another interesting recorded statistic is the count of \acrlong{sloc}. This count exposes one of the criticisms commonly directed at Go - verbose error handling. Although the code is semantically simpler (no manual memory management, higher level language constructs) the \gls{sloc} count is in fact identical to that of \textit{streets4C}. This is partially the result of the common four line idiom to handle errors. A function that could fail typically returns two values. The desired result and an error value. If the function failed to execute successfully the error value will indicate the source of the failed execution. Otherwise this value will be \shinline{nil} signalling a successful completion. This pattern is used three times in this simple first phase alone which results in 12 lines.
\\
\lstinputlisting[caption={Idiomatic error handling in Go}, label={lst:error_handling.go}, style=go]{code/error_handling.go}

Considering the aforementioned simplicity \textit{streets4Go}'s performance characteristics are very promising. Although in its basic form about four to five times slower than the C solution the parallelized version achieves similar performance to \textit{streets4C}. This version was only included since the library was already based on a variable number of \glspl{goroutine} which made the parallelzation a matter of changing an environment variable in the Go runtime. While this change required only the addition of a single line, the C abstraction \shinline{osmpbfreader} might not even be parallelizable without considerable changes to its architecture. This truly shows the power of language level parallelization mechanics and confirms the choice of Go as a candidate in this evaluation.

\subsection{Rust}
\label{subsec:Implementation::Counting::Rust}

\textit{streets4Rust} also had the advantage of an existing library to use for \gls{osm} decoding which is called \textit{osmpbfreader-rs}\fnote{\url{https://github.com/texitoi/osmpbfreader-rs}}. Similar to Go the dependency management was extremely convenient and simple. The only changes necessary were an added line in the Cargo manifest (Cargo.toml) and an \shinline{extern crate osmpbfreader;} in the crate root \shinline{main.rs}. After that \mdinline{cargo build} downloaded the dependency (which in this case meant cloning the \shinine{git} repository) and integrated it into the compilation process.

Compared to C and Go \textit{streets4Rust} required a medium amount of development time and had the lowest \gls{sloc} count in this phase. This can mainly be attributed to the library's use of common Rust idioms and structures like \shinline{iterators} and \shinline{enums}. Unlike C enums, which are basically named integer constants, the Rust variant provides a lot more features like beeing useable in pattern matching expressions. The next \hyperref[lst:osm_decoding.rs]{Listing} shows the complete decode part of this stage which is very compact and easy to understand.  //add implementation details of the lib? (chained interators)
\\
\lstinputlisting[caption={\gls{osm} decoding in Rust}, label={lst:osm_decoding.rs}, style=rust]{code/osm_decoding.rs}

The function \mdinline{blocks::iter} returns an enum value which gets pattern matched on to determine which counter should get incremented. While this example does not actually use any fields of the objects it would be a simple change to destructure the enum values and retrieve the structures containing the data.

The execution time highlights another important factor in regards to Rust's matureness as a language. The optimized version is more than ten times faster then the binary produced by default options. This is mostly due to the fact that the Rust \gls{llvm} frontend produces bloated byte code which does not get optimized on regular builds. That is also the reason release builds take substanstially longer. It simply takes more time to optimize (and therefore often shrink) \gls{llvm_ir} instead of emitting less code in the first place. Although the code generation gets improved steadily it is not a big focus until version \shinline{1.0} is released but the Rust core team knows about the issue and it is a high priority after said release.

Nonetheless the release build shows the power of \gls{llvm}'s various optimization passes. \textit{streets4Rust} achieves the second best single threaded performance after C with a run time of 2.72 seconds which is impressive considering the vastly shorter development time and lowest \gls{sloc} count across all candidates.

\subsection{Comparison}
\label{subsec:Implementation::Counting::Comparison}

\section{Building a basic graph representation}
\label{sec:Implementation::Graph_Representation}

The second milestone was to develop a graph structure to represent the street network in memory. Like in \textit{streets4MPI} random nodes from this data would then be fed to Dijkstra's shortest path algorithm to simulate trips. Since all applications should be parallelized later on the immutable data (such as the edge lengths, \gls{osm} IDs and adjecency lists) needed to be stored separately from the changing data the algorithm required (such as distance and parent arrays). To achieve this all implementations have a \shinline{graph} structure holding the immutable data and a \shinline{dijkstragraph} structure to store volatile data for the algorithm alongside some kind of reference (or pointer) to a graph object.

Since this milestone included a preliminary implementation of the actual algorithm it required the use of a priority queue which was not directly available in all languages. Considering this fact the third milestone already highlighted some differences in comprehensiveness of the different standard libraries.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        \gls{sloc} (total)
            & 385
            & 196
            & 170 \\

        Development time (hours)
            & 02:30:32
            & 01:06:06
            & 01:14:28 \\
        \bottomrule
    \end{tabular}
    \caption{Milestone 2: Building a basic graph representation}
    \label{tb:milestone2}
\end{table}

\subsection{C}
\label{subsec:Implementation::Graph_Representation::C}
// TODO: shorten this? other sections are shorter

As seen in \autoref{tb:milestone2} this stage resulted in a much higher \gls{sloc} count for C. This is due to the fact that development took place in another source files. To encapsulate graph functionality properly a new file called \shinline{graph.c} was created. Following established conventions this meant also creating a matching header (\shinline{graph.h}) to be able to use the newly written code in the main application. While this separation is decently useful to not have to clobber you source file with structure definitions it also introduces a fair bit of redundancy. Functions are declared in the header and implemented in the source files which means the signature appears twice. In addition C had the unfortunate problem of not having a proper implementation of a priority queue easily available which required the addition of another source file / header combination (\shinline{util.c/h}). This increased the \gls{sloc} count even further and added some additional development time as well.

At this point it became clear the C version would not be created dependency free. Advanced data structures such as hash tables or growing arrays are essential when properly modelling a graph and the choice was made to use the popular \textit{GLib}\fnote{\url{https://developer.gnome.org/glib/stable/}} to provide these types. It is a commonly used library containing data structures, threading routines, conversion functions or macros and much more. Since both Rust and Go's standard library are mch more comprehensive then C's the addition of GLib to the project is easily justified.

Implementing the graph representation itself was very straight forward. Similar to the mathematical representation a \shinline{graph} in \textit{streets4C} consists of an array of \shinline{node}s and \shinline{edge}s. To be able to map from \gls{osm} IDs to array indices two hash tables were added using \lstinline[style=c]{long}s as keys and \lstinline[style=c]{int}s as values. The \shinline{dgraph} structure can be created with a pointer to an existing \shinline{graph} and is then able to execute Dijkstra's \acrshort{sssp} algorithm.
\\
\lstinputlisting[caption={Graph representation in C}, label={lst:graph_representation.c}, style=c]{code/graph_representation.c}

All structures contain little more than the expected data bseides the \shinline{cur} field in \shinline{dgraph}. It needed to be added since Glib's \shinline{GHashTable} only support operations on all key-value-pairs via a function pointer with a single extra argument. Since the algorithm at on particular required access to the currently explored node's index as well as the distance and parent arrays the index needed to be stored in the struct itself.

While the additional field was a minor inconvenience other problematic aspects were the code bloat and added unsafety intrduced by the use of \shinline{GHashTable}s\fnote{The hash table implementation provided by GLib}. Since C is not typesafe by design and does not allow for true generic programming via type parameters nearly all generic code is written using \lstinline[style=c]{void*}. This leads to very verbose code because of the high amount of casts involved when accessing or storing values inside the data structures mentioned earlier.

Another complication was the use of integers as keys in \shinline{GHashTable}. It requires both key an value to be a gpointer (which is a platform independant \lstinline{void} pointer) which forces the programmer to either allocate the integer key on the heap or explicitly cast it to the correct type. This works well using a macro provided by GLib until the number zero appears as a value because it represent the \shinline{NULL} pointer which GHashTable also uses to indicate a key was not found in the hash table.

The implementation of Dijkstra's algorithm was not particularly hard only more verbose than expected. As mentioned the GHashTable only provides iterative access through an extra function. As a consequence the step commonly referred to as \textit{relax edge} is contained in a separate function that get passed to \shinline{g\_hash\_table\_foreach}. In combination with the conversion macros and temporary variables the code bloats up.

All in all the experience was poor compared to the other languages. The verboseness and missing safety lead to the highest development time and \gls{sloc} count by far. The time was spent debugging some obscure errors introduced by the excessive casting which might have been avoided by a more sophisticated typesystem.

\subsection{Go}
\label{subsec:Implementation::Graph_Representation::Go}

For Go a similar approach was chosen. The graph is again mostly composed of two arrays holding all nodes and edges. However unlike the native C variants Go's \shinline{slices} and \shinline{maps} are dynamically growing which means the constructor function of the graph does not require capacity parameters. In general the development process was once again very smooth and simple which shows in the short time spent and the low \gls{sloc} count.
\\
\lstinputlisting[caption={Graph representation in Go}, label={lst:graph_representation.go}, style=go]{code/graph_representation.go}

As the \hyperref[lst:graph_representation.go]{Listing} shows the structures are nearly identical to their C counterparts. Only the current node index in DijkstraGraph was not required since Go allows for much better iteration through maps. It is also interesting to note that Go supports (and even encourages) the declaration of multiple fields of the same type on the same line. Although this was used only two times in the snippet it shrinks the line count while keeping the code understandable since two fields with identical types are often related anyway.

As stated in the introductory part Dijkstra's algorithm depedends on a priority queue. Despite the fact that Go's standard library does not directly provide a ready-to-use implementation thereof the required steps to achieve this were minimal. The package \shinline{container\textbackslash heap}\fnote{\url{http://golang.org/pkg/container/heap/}} offers a convenient way to work with any kind of heap. The only restriction is that the underlying data structure implements a special interface containing common operations used to \textit{heapify} the stored data. Since interfaces are implicitly implemented on all structures which present the necessary methods it was a simple task to create a full featured priority queue on top of a slice by writing just four trivial methods.
\\
\lstinputlisting[caption={Priority queue in Go}, label={lst:priority_queue.go}, style=go]{code/priority_queue.go}

While the heap implementation was provided by the standard library (which is likely to be correct) it required the custom methods of \autoref{lst:priority_queue.go} to be correct. At this point Go's builtin test functionality came in handy. All it took to test the custom implementation was to create another file called \shinline{util\_test.go} (adding the suffix ``\_test'' to the already existing file \shinline{util.go}) and write a simple test. No import besides the \textit{testing} package were needed since the code resided in the same package as the main application and all test got executed with a single call of \mdinline{go test} from the commandline. In contrast the C implementation of the queue required the setup of an additional source file including a regular main function which then had to manually compiled and run. In addition some basic error formatting and output\fnote{Which potentially could also contain errors(!)} had to be written to properly locate potential errors in the implementation. Although all test related statistics are not counted in either language, Go's testing workflow is clearly superior to the manual, errorprone C approach.

All things considered this milestone was easily implemented in Go. The builtin container datastructures simplified the structure definitions while the provided heap implementation had a very low entry barrier and produced quick results. This reflect in the statistics which are on par with the Rust version discussed in the next section. \\technically a subsection?

\subsection{Rust}
\label{subsec:Implementation::Graph_Representation::Rust}

The original plan for the Rust implementation was to use direct references between nodes and edges of the graph to allow for easy navigation during the algorithm. Combined with the guarantees the typesystem offers it seemed to be a unique approach offering both convenient access and memory safety. Unfortunately this approach was quickly dismissed since it would have essentially created circular datastructures. While those are definitely possible to implement, it takes some \shinline{unsafe} marked code and a lot of careful interface design to retain the aforementioned safety. Due to once again time restrictions a architecture to the Go and C variant was implemented

The interesting differences in contrast to the previously introduced structures are located in \shinline{DijkstraGraph}. The \shinline{queue} field has the type \shinline{BinaryHeap} which is located in the standard library. This already shows that Rust is the only language out of the candidates which contains a complete implementation of this datastructure as part of the core libraries. While a priority queue is certainly not an essential component of every program it was required for this algorithm and having it available right from the start was beneficial to the development.
\\
\lstinputlisting[caption={DijkstraGraph in Rust}, label={lst:graph_representation.rs}, firstline=24, style=rust]{code/graph_representation.rs}

The other interesting part is the type of the \shinline{graph} field. As mentioned earlier the struct calculating the shortest paths needs a reference to the immutable graph data. Ideally one would like to encode this immutability in the type itself. This is where Rust's typesystem shines. As mentioned in the \hyperref[subsec:State_of_the_art::Candidates::Rust]{language introduction} regular references only allow read access. This means DijkstraGraph cannot (accidentally or intentionally) modify the referenced Graph instance or any of its fields just because the reference does not allow this. This comes in handy later in a parallel scenario where multiple threads are reading data from the graph while calculating shortest paths. The readonly reference (in Rust terms ``a shared borrow'') ensures no data races can happen when accessing the graph concurrently.

From a statistics standpoint Rust is evenly matched with Go. While \textit{streets4Go} took a little less time to write, \textit{streets4Rust} has a few less lines. This mostly came down to the heap implementations being available in the standard library (which means less code had to be written) and the mentioned deviation from the original implementation plan, adding some additional development time.

\subsection{Comparison}
\label{subsec:Implementation::Graph_Representation::Comparison}

Although this milestone did not contain any performance measurements it clearly highlighted and emphasized the original argument for a new language in \acrlong{hpc}. In scenarios where complex data structures beyond a simple array are required C fails to deliver an easy development experience. This was mostly due to the lack of ``true'' generic programming limiting the expressiveness of the implemented structures and algorithms. Since all casts in C are unsafe anyway but required to enable genericity, one slight type error, which a rigid typesystem might have been prevented from even compiling, can cause segmentation faults which are hard to trace and correct. This clearly underlines that C is not the optimal choice for developing complex high performance applications.

Go and Rust performed equally well in this stage. Both include a typesystem suited to safely use generic containers and provide a sufficient standard library for a decent implementation of a shortest path algorithm. Although Go's generics are limited to builtin types like slices and maps this was not an issue in this stage since no generic methods had to be written. Rust had the unique advantage to be able to express application semantics (graph data is immutable to the algorithm) in the typesystem. Although that did not solve any immediate problems in the implementation it can help to prevent a whole class of defects as described in the previous section.

\section{Verifying structure and algorithm}
\label{sec:Implementation::Verification}

The next goal was to verify the implemented algorithms on some sample data. To achieve this a sample graph with ten nodes and about 15 edges was constructed followed by a shortest path calculation for each node. Although performance was measured it was not the core focus of this stage since the input data was very small and not representative of the \gls{osm} data. Nonetheless the execution time reveals some interesting differences between the competitors.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        \gls{sloc} (total)
            & 633
            & 275
            & 232 \\

        Development time (hours)
            & 01:53:30
            & 01:16:49
            & 01:04:38 \\

        Execution time (seconds)
            & 0.004 (-O0)
            & 0.686
            & 0.007 (-O0) \\
            & 0.003 (-O3)
            & % intentionally blank since no parallel version was build
            & 0.005 (-O3) \\

        Allocation count
            & 108
            & 519
            &  47 \\

        Free count
            & 106\fnote{Due to the use of GLib some global state remains reachable after exiting. This is likely intended behaviour and not a memory leak (see: \url{http://stackoverflow.com/a/4256967}).}
            & 169
            &  47 \\

        Allocation amount (bytes)
            & 7,868\fnote{2,036 bytes were in use at exit see footnote 14}
            & 53,016
            & 22,792
        \bottomrule
    \end{tabular}
    \caption{Milestone 3: Verifying the implementation}
    \label{tb:milestone3}
\end{table}

\subsection{C}
\label{subsec:Implementation::Verification::C}

Unsurprisingly the C implementation has the lowest execution time among the compared languages. Unfortunately the performance was once again paid with a high development time following the trend from previous milestones. In this phase a lot of time was invested into debugging the custom priority queue implementation. Although the there was a simple test performed in the last stage the real data revealed a bug when queuing zero indices. Similar to the GHashTable the zero index was casted to a void pointer and treated as null which caused errors during the pop operation later on. Unfortunately the defect manifested in the typical C style with a nondescriptive segmentation fault.

Performancewise C proves once again why it is one of the two major players in \gls{hpc}. The execution time is unbeaten (even unoptimized) and the allocation amount is the lowest among the contestants by far. As explained in the annotation the mismatch in \shinline{malloc} and \shinline{free} calls can be explained by the inclusion of GLib. For its advanced features like memory pooling it retains some global state which \textit{valgrind} mistakenly classifies as a potentital leak.

\subsection{Go}
\label{subsec:Implementation::Verification::Go}

The verification in Go took a little bit longer than expected. Although the implementation itself was quickly completed it exposed some errors in the original graph structure. The main problem was the initialization of the graph slices. The previous implementation used the builtin function \shinline{make} to create a slice with an initial capacity. When adding nodes to the slice later another builtin function \shinline{append} was used under the assumption the slice would be empty initially. This was not the case since Go had just filled the whole slice with empty node objects. This caused errors later down the line when these empty objects were used in Dijkstra's algorithm. The problem was later solved by changing the creation function from \shinline{make} to \shinline{new}. This method just creates a new array and lets the slice point into it reallocating later if neccessary.

While the actual change in code was minimal the origin of this defect are interesting. As mentioned above all three functions interacting with the slice are built into the language itself. This approach was explicitly chose to make common operations (like creating, retrieving the length or capacity) on common types (like slices, arrays and maps) more accessible. Unfortunately these functions obviously have slightly different meanings on different types resulting in some unexpected behaviour. This is certainly something which can be picked up when using Go for extended periods of time but for newcomers especially if can cause some confusion and while the new variant with \shinline{new} works it is unclear whether this is the ideomatic way to create growing slices.

From a performance standpoint \textit{streets4go} falls short compared to the other implementations. This can mostly be explained by the Go runtime. It needs some initial setup time and memory which increases the allocation amount and prolongs execution time. Since this was a very small benchmark only used to validate the implementations these little ``static costs'' make up a much higher percentage of the total statistics.

\subsection{Rust}
\label{subsec:Implementation::Verification::Rust}

During the implementation an effort was made to randomize the order of languages between milestones. It just happened that Rust was the last candidate in this phase since an update in the nightly version of the compiler broke the \gls{protobuf} package on which the \gls{osm} library depended on. Although the author was quick to update the code to the changes there was a downtime of about three to four days where the development could not continue since the other versions were finished but \textit{streets4Rust} did not build. Although this was the only case where the code was majorly broken for larger timespan it still effectively halted the whole process. Luckily the first stable release is scheduled for shortly after the deadline of this thesis so this should not really be a problem later on.

In this case it was even an advantage that the Rust version was developed last since it revealed a critical error in the other implementations. When creating the sample graph all data was derived from indices of two for loops. The assumption was that edges created in the second loop would only reference existing nodes created in the first one. Since both other implementations did not crash or produce any errors the creation code was not thoroughly verified. Running the same sample data through the Rust application revealed the error. The \shinline{add\_edge} method did not check whether the edge ids passed as arguments were previously added to the graph. This is mandatory since the ids get converted to array indices to be able to add the nodes in the respecting adjecency lists. A map lookup in Go or C is achieved via the indexing operator which then returns and the value element associated with the given key. Obviously this operation can fail when the given key is not found in the map. While both C and Go indicate this error case with a return of zero the possibility of failure is directly encoded in the corresponding Rust. Instead of simply returning the value it returns an \shinline{Option} which is a Rust enumeration is either containing a value or \shinline{None}. This type is a perfect fit for functions which might fail to return the desired value since it shifts the responsibility to deal with the failure to the callee which can potentially recover or otherwise abort completely. The following Listings show the id to index conversion in Go and Rust highlighting the differences.
\\
\lstinputlisting[caption={Map lookup in Go}, label={lst:map_lookup.go}, style=go]{code/map_lookup.go}
\\
\lstinputlisting[caption={Map lookup in Rust}, label={lst:map_lookup.rs}, style=rust]{code/map_lookup.rs}

Although not shown here the C version behaves identical to the Go version but uses a static function \shinline{g\_hash\_table\_lookup}. While the indexing seems more convenient is does not offer precise feedback over the success state of the operation. In this context this is especially critical since zero is a semantically valid index to retrieve. As mentioned above the return value of Rust's \shinline{HashMap.get} is an \shinline{Option} and as such it has to be ``unwrapped'' to get the contained value. This method panics the thread if called on a \shinline{None} value which is exactly what happened when the application processed the sample data. Further investigation then revealed a missing check whether the key is contained in the map which got silently ignored in both other applications. This is a good exaple of how a sophisticated typesystem can prevent potential errors through descriptive types.

The statistics for this milestone are once again very promising for Rust. With the lowest \gls{sloc} count as well as develoment time it still remains competitive with the execution performance of C. The allocation count also hints that Rust's vectors reallocate larget than the GHashTable from GLib. While the count of function calls is smaller the amount of memory allocated is larger.

\subsection{Comparison}
\label{subsec:Implementation::Verification::Comparison}

This milestone highlighted the importance of strong typesystems in particular. They can prevent bugs which would otherwise require intensive testing to be even noticed in the first place. In addition C once again comes in last in terms of developer productivity and while the performance benefit is still in its favor Rust reaches a similar speed with less implementation time. While Go is certainly not as fast as the other two languages as of yet it is a very comfortable language. // feels short/wrong?

\section{Sequential benchmark}
\label{sec:Implementation::SequentialBenchmark}

In this milestone runtime performance came back into the main focus. Since the algorithms at this point were proven to work correctly it could now be applied to real geographical data. The main technical challenge here was to efficiently process the input file while ideally directly filling the graph with the accumulated data. The caveat was the handling of \gls{osm} \shinline{ways} which are later represented by one or more edges in the graph. The input format lists all ids of the nodes which are part of the way but these nodes might not have been processed and added to the graph yet. This forced the implementations to retain the ways' data in some way and construct edges from that data in a second step.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        \gls{sloc} (total)
            & 757
            & 359
            & 292 \\

        Development time (hours)
            & 01:14:32
            & 00:56:16
            & 00:45:20 \\

        Execution time (hours)
            & 08:34:01 (-O3)
            & 09:08:19
            & 07:31:37 (-O3) \\

        Memory usage (MB)\fnote{Obtained via htop (\url{http://hisham.hm/htop/}) at the time of shortest path calculation}
            & 994
            & 1551
            & 2235 \\

        \bottomrule
    \end{tabular}
    \caption{Milestone 4: Sequential benchmark}
    \label{tb:milestone4}
\end{table}

\subsection{C}
\label{subsec:Implementation::SequentialBenchmark::C}

For \textit{streets4C} the most time was spent on dealing with the edges. As mentioned in the introductory part they need to be saved and added later. This either required knowing the amount of edges beforehand (to be able to preallocate an array large enough to store all information) or to use a dynamically growing array to store them as they get processed. Since the amount of edges is not stored in the \gls{osm} file, the first approach would have to read the whole input file twice to count edges (and ideally nodes too) first and then parse the actual data in the second run. To prevent this the second design as implemented.

Of course reallocating arrays are not part of the C language or standard library and the application had to rely on GLib once again. The used types were \shinline{GPtrArray} to store pointers to the heap allocated \textit{node} and \textit{edge} structures and the regular \shinline{GArray} to store the \gls{osm} ids of the constructed edges. With this implementation the file only needed to get read once creating the actual values and counts (useful to pass to the graph creation method as capacities later) in the process.

Another option would have been to rewrite part of the graph structure to use GArrays internally for storing edges and nodes in the first place. This idea was not realized to keep the number of external data structures in the graph representation minimal. However that change would have simplified this milestone considerably.

The performance statistics from this phase contains the first real surprise. \textit{streets4C} does not have the lowest execution time. Rust outshines the C implementation by more than an hour. This might reflect a suboptimal architecture on the C side which can be traced back to my limited experience with the language. However this might very well be reflective of a scientist with similar limited programming skills. Considering the development time and \gls{sloc} count the result is even more alarming. The redeeming factor of the C variant is the memory footprint which is the lowest among the three languages. Although memory is typically not as critical as processing time it is still an important criteria when evaluating \gls{hpc} applications.

\subsection{Go}
\label{subsec:Implementation::SequentialBenchmark::Go}

This phase did not offer any difficult technical challenges for the Go implementation. Nodes could be added right as they were encountered while parsing whereas edges were temporarly stored in a growing slice and were appended in a second pass.

An essential function for this milestone was the calculation of the length between two nodes based on latitude and longitude. Based on \textit{streets4MPI} the haversine formula\fnote{\url{http://en.wikipedia.org/wiki/Haversine_formula}} was chosen to perform this calculation. This kind of mathematical formulae can be implemented very compactly in Go. Especially the assignments of multiple variables in the same line helps readability and reduces the amount of lines required.
\\
\lstinputlisting[caption={Haversine formula in Go}, label={lst:haversine.go}, style=go]{code/haversine.go}

While the \hyperref[lst:haversine.go]{Listing} is a bit small in width the advantages should be clearly visible. The multiline assignment are very compact and are useful for these shortlived intermediate results. In Go all identifiers are located on the left side of the assignment while a multi assignment in C consists of multiple assignment separated with a comma. This mix of identifiers and values takes some additional time to mentally parse - a problem which the Go way does not suffer from.

In the performance comparison Go comes in at the third place as expected but the gap to C is actually not as big predicted. Interestingly \textit{streets4Go} has only the second highest memory consumption despite being garbage collected and therefore lacking deterministic destruction. This differentiates Go from other garbage collected languages like \textit{C\#} or \textit{Java} which encourage ``allocations hevy programming'' under the premise that memory cannot leak and can therefore be allocated often.

\subsection{Rust}
\label{subsec:Implementation::SequentialBenchmark::Rust}

The Rust implementation follows the same pattern as the Go version. Nodes are added to the graph as they are decoded while edges are stored in a vector to add later. There was a caveat though where Rust's ownership tracking typesystem

After the input data has been processed the \shinline{edges} vector contains all edges found in the file. Which means in Rust terms that the vector \textit{owns} all objects inside it. On the other hand the \shinline{add\_edge} method also needs to take ownership of the edge argument passed to it. This was a deliberate choice while designing the interface since the graph should own all edges and nodes it consists of. This creates a conflict because indexing the vector only returns a reference to the object. The solution was to use a moving iterator to remove the objects from the vector to be able to pass them to \shinline{add\_edge}. In addition the two node ids of the edge, which were stored in additional vectors, needed to be retrieved the same way. To achieve this the two iterators were zipped and as a consequence all required variables could be in scope at the same time.
\\
\lstinputlisting[caption={Zipped iterators in Rust}, label={lst:zipped_iterators.rs}, style=rust]{code/zipped_iterators.rs}

The \shinline{Iterator.zip} method takes an iterator and returns a composite iterator which yields elements from the two as a pair. Here \shinline{indices} is a vector of pairs of i64 (Rust's 64-bit integer) so the iterator created by zip yields a pair of type \shinline{(edge, (i64, i64))}. Also the edge length had to be calculated before the edge could be added to the graph. This meant the \shinline{mut} keywork had to be added in front of the edge variable. The resulting expression \lstinline|for (mut e, (n1, n2)) in edges.into_iter().zip(indices.into_iter())| looks very complicated but is actually pretty simple when taken apart. These tangled statements are probably the major disadvantage of the complex typesystem. There are a lot of sigils which sometimes even have double meanings.

The performance comparison was specifically interesting in this stage because Rust was actually ahead of C for the first time. It is also remarkable that the development time and \gls{sloc} count are the lowest of the three languages compared. This means the usual tradeoff between performance and productivity does not apply in this particular case and Rust straightup beats Go and C in all three tracked categories which is impressive.

\subsection{Comparison}
\label{subsec:Implementation::SequentialBenchmark::Comparison}



\section{Parallel benchmark}
\label{sec:Implementation::ParallelBenchmark}

Last but not least it was time to parallelize the calculations. Because the algorithm itself is not very easy to execute concurrently the choice was made to calculate multiple shortest paths in different threads. Also the main loop over the first 100.000 nodes was already in place from the previous milestone and so only this block had to be updated to run in parallel.

It is also important that the parallelized code does not make any use of the computed results as the previous versions did not do that either. In concurrent scenarios this becomes a separate problem because of synchronization issues. Although it is not included in the implementations each of the following sections will describe possible strategies to deal with the calculated results.

\begin{table}[htb]
    \centering
    \begin{tabular}{llll}
        \toprule
        % Header
            & C
            & Go
            & Rust \\
        \midrule

        \gls{sloc} (incl. previous stages)
            & 777
            & 381
            & 314 \\

        \gls{sloc} (final)
            & 668
            & 285
            & 253\\

        Development time (hours)
            & 00:08:11
            & 00:07:56
            & 00:27:23 \\

        Execution time (4 threads) (hours)
            & 03:22:21 (-O3)
            & 03:47:30
            & 02:32:06 (-O3) \\

        Memory usage (MB)\fnote{Obtained via htop (\url{http://hisham.hm/htop/}) at the time of shortest path calculation}
            & 994
            & 1551
            & 2235 \\

        \bottomrule
    \end{tabular}
    \caption{Milestone 5: Parallel benchmark}
    \label{tb:milestone5}
\end{table}

\subsection{C}
\label{subsec:Implementation::ParallelBenchmark::C}

As mentioned in the previous chapter OpenMP was the framework of choice to parallelize \tetit{streets4C}. Given this there were two possible approaches to consider. Either the \shinline{for} pragma applied to the existing loop or a regular \shinline{omp parallel} block.

\subsection{Go}
\label{subsec:Implementation::ParallelBenchmark::Go}

\textit{streets4Go} obviously used goroutines for concurrent execution. As the development time shows the implementation was really simple and convenient. Similar to the C variant the only required change

\subsection{Rust}
\label{subsec:Implementation::ParallelBenchmark::Rust}


\subsection{Comparison}
\label{subsec:Implementation::ParallelBenchmark::Comparison}

\section{Preparing execution on the high performance machine}
\label{sec:Implementation::ClusterPreparation}
