\chapter{State of the art}
\label{ch:State_of_the_art}

\abstract{%
This chapter describes the current state of the art in high-performance computing. The dominance of Fortran and C is explained and questioned in~\autoref{sec:State_of_the_art::Paradigms}. After that all considered language candidates are introduced and characterized.
}

- state of C and Fortran (section name?)

- technological advancements in low level languages
    - static analysis
    - ..
    -> But no real adaption possible, because language level support is missing (already included in introduction)

\section{Programming paradigms in Fortran and C} % change name?
\label{sec:State_of_the_art::Paradigms}

As stated in~\autoref{sec:Introduction::Motivation} high-performance computing is largely dominated by C and Fortran and although their trademark is mostly performance these two languages achieve this in very different ways. Unfortunately both approaches are not completely safisfying and could be improved.

Fortran is the traditional choice for \gls{hpc} applications and it's typesystem is very much accustomed to that area. As the name suggests~\fnote{FORTRAN is an acronym for FORmula TRANslation} it was originally developed to allow for easy computation of mathematical formulae on computers. In spite of Fortran beeing one of the oldest programming languages it is actually fairly high-level. It provides \gls{intrinsic} functions for many common mathematical operations such as matrix multiplication or trigonometric functions and a builtin datatype for complex numbers. In addition memory management is nearly nonexistent. In earlier versions of Fortran it was not possible to explicitly allocate data and even in programs writtine in newer revisions of the language allocation and memory sharing often only account for a small fraction of the source code.

While this high-level paradigm of scientific programming is certainly well suited for a lot of applications, especially for scientists with mathematical backgrounds, it can also be insufficient in some edge cases. Notably in performance critical sections the \gls{intrinsic} functions sometimes are just not good enough and the programmer has to fall back to manual solutions or external libraries. Because Fortran does not offer fine grained control over memory or other resources some algorithms cannot be fully optimized which can limit performance. Of course this is not the general case and normally the compiler can generate efficient code but in machine dependant regions like caches or loop unrolling Fortran simply does not give the programmer enough control to finetune every last bit.

C on the other hand approaches performance totally different. Developed as a general purpose language it provides the tools to build efficient mathematical functions and datatypes which in turn require a lot more micromanagent than their equivalents from Fortran.


// remove or rephrase this (maybe as the last aragraph of this section?)
The main drawback of both languages is their age. Although new revisions are regularly aproves Fortran and C strive to be backwards compatible for the most part. This has some very serious consequences especially in their respective syntax. A lot of features of newer standards are integrated suboptimally to preserve backwards compatability.


// Candidates here for now might need another chapter for those
\section{Language candidates}
\label{sec:State_of_the_art::Candidates}

As previously stated Go and Rust were chosen to be evaluated in the context of \gls{hpc}. This section aims to provide a rough overview of all language candidates that were considered for further evaluation in this thesis.

\subsection*{Python}
\label{subsec:State_of_the_art::Candidates::Python}

Python is an interpreted general-purpose programming language which aims to be very expressive and flexible. Compared with C and Fortran which sacrifice feature richness for performance, Python's huge standard library combined with the automatic memory management offers a low border of entry and quick prototyping capabilities.

%  wording
As a matter of fact many introductory computer science courses at universities in the United States recently switched from Java to Python as their first programming language.~\cite{GUO14, intro_py} This allows the students to focus on core concepts of coding and algorithms instead of distracting boilerplate code.
\\
\lstinputlisting[caption={FizzBuzz in Pyhon 3.4}, label={lst:example.py}, style=python]{code/example.py}

In addition to the very extensive standard library the Python community has created a lot of open source projects aiming to support especially scientific applications. There is NumPy\fnote{\url{http://www.numpy.org}} which offers efficient implementations for multidimensional arrays and common numeric algorithms like Fourier transforms or MPI4Py\fnote{\url{http://www.mpi4py.scipy.org}}, an \gls{MPI} abstraction layer able to interface with various backends like OpenMPI or MPICH. Especially the existance of the latter shows the ongoing attempts to use Python in a cluster environment and there have been successful examples of scientific high performance applications using these libraries( //need ref ).

Unfortunately dynamic typing and automatic memory management come at a rather high price. The speed of raw numeric algorithms written in plain Python is almost always orders of magnitude slower than implementations in C or Fortran. As a consequence nearly all of the mentioned libraries implement the critical routines in C and focus in optimizing the interop (// wording) experience between the two languages. This often means one needs to make tradeoffs between idiomatic Python - which might not be transferable to the foreign language - and maximum performance. As a result performance critical ython code often looks like it's equivalent written in a statically typed language. The more terseness Python loses because of this, the less desireable it becomes to use in \gls{hpc} since one could just fall back to C for a similar experience.

In conclusion Python was not chosen to be further evaluated because of the mentioned lack of performance (in pure Python). This might change with some new implementations emerging recently though. Most of the problems discussed here are present in all stable Python implementations today (most notably \textit{Cython} and \textit{PyPy}) but new projects aim to improve the execution speed in various ways. \textit{Medusa} compiles Python code to Google's Dart to make use of the underlying virtual machine. Although these ventures are still in early phases of development, first early benchmarks promise drastic performance improvements. Once Python can achieve similar execution speed to native code it will become a serious competitor in the \gls{hpc} area.

\subsection*{Erlang}
\label{subsec:State_of_the_art::Candidates::Erlang}

Erlang is a relatively niche programming language originally designed for the use in telephony applications. It features a high focus on concurrency and a garbage collector which is enabled through the execution inside the \gls{beam} virtual machine. Today it is most often used in soft real-time computing~\fnote{see \url{https://en.wikipedia.org/wiki/Real-time_computing}} because of it's error tolerance, hot code reload capabilities and lock-free concurrency support.~\cite{intro_erlang}

Erlang has a vary unique and specialized syntax which is very different from C-like languages. It abstains from using any kind of parentheses as block delimiters and instead uses a mix of periods, semicolons, commas and arrows (\mdinline{->}). Unfortunately the rules for applying these symbols are not very intuitive and may even seems random for newcomers at times.

One core concept of Erlang is the idea of processes. These lightweight primitives of the language are provided by the virtual machine are neither direct mappings of operating system threads nor processes. One the one hand they are cheap to create and destruct (like threads) but do not share any address space or other state (like processes). Because of this the only way to communicate is through message passing which can be handled via the \mdinline{receive} keyword and send via the \mdinline{!} operator.~\cite{erlang_phd, intro_erlang}
\\
\lstinputlisting[caption={Erlang example}, label={lst:example.erl}, style=erlang]{code/example.erl}

Conceptionally Erlang offers various constructs known from functional languages like pattern matching, clause based function definition and immutable variables but the language as a whole is not purely functional. Rather each erlang process in itself (ideally) behaves pure (meaning the result of a function depends solely on its input) while the collection of processes interacting which each other through messages of course contain state and side effects.

Erlang was considered as a possible candidate for \gls{hpc} because of its concurrency capabilities. The fact that processes are a core part of the language and are rather cheap in both creation and destruction seems ideal for high performance applications often demanding enormous amounts of parallelism. Sadly Erlang suffers from what one might call over specialization. The well adapted type system makes it very suited for tasks where concurrency is essential like serverside request management, task scheduling and other services with high connection fluctuation, but ``The ease of concurrency doesnâ€™t make up for the difficulty in interfacing with other languages.''~\cite{erlang_fps} Even advocates of Erlang say they would not use it for regular business logic. In \gls{hpc} most of the processing time is spent solving numeric problems. These are of course parallelized to increase effectiveness but the concurrency aspect is often not really inherent to the problem itself. Because of this Erlang's concurrency capabilities just do not outweigh it's numeric slowness for traditional \gls{hpc} problems.~\cite{erlang_guide}

% - brief history?
%
% - code example (not hello world rather show message passing)
%
% - Upsides
%     - Great concurrency
%     - Message passing is default (no locks)
%     - Hot swap?
% - Downsides
%     - Bad interfacing to other languages
%     - Weird syntax
%     - Limited (community/support?)


\subsection*{Go}
\label{subsec:State_of_the_art::Candidates::Go}

Go is a relatively young programming language which focusses on simplicity and clarity while not sacrificing too much performance. Initially developed by Google it aims to ``make it easy to build simple, reliable and efficient software'' (//cite). It is statically typed, offers a garbage collector, basic type inference and a large standard library. Go's syntax is loosely inspired by C but made some major changes like removing the mandatory semicolon at the end of commands and changing the order of types and identifiers. It was chosen as a candidate because it provides simple concurrency primitives as part of the language (so called \textit{goroutines}) while having a familiar syntax and beeing reasonably performant~\cite{intro_go}. It also compiles to native code without external dependencies which makes it usable on cluster computers without many additional libraries installed.

The chosen code example demonstrates two key features which are essential to concurrent programming in Go - the already mentioned goroutines as well as channels which are used for synchronization purposes. They provide a way to communicate with running goroutines via message passing.
\\
\lstinputlisting[caption={Go concurrency example}, label={lst:example.go}, style=go]{code/example.go}

Initially developed for server scenarios Go has seen production use in many different areas. At Google it is used for various internal project such as the download service ``dl.google.com'' which has been completely rewritten from C++ to Go in 2012. The new version can handle more bandwith while using less memory. It is also noteable that the Go codebase is about half the size of the legacy application with increased test coverage and performance~\cite{go_dl_google}.

While Go's focus on simplicity is admireable it has also been it's greatest point of criticism. The language feature set is very carefully selected and rarely extended. It even misses some of the most natural constructs which a programmer might expect in a reasonably high-level language - the main example for this beeing generics. As of the time of this writing Go does not offer the common concept of generic types or functions and the authors have stated this is not a big priority at the moment.

One other important fact - especially for high-performance computing - is the mandatory garbage collector. Go completey takes the burden of memory management out of the hands of the programmer and relies on the embedded runtime to efficiently perform this job. This makes it impossible to predictably allocate and release memory which can lead to performance loss. This also means the Go runtime has to be statically linked into every application. Although that might not be important for bigger codebases it increases the binary size considerably.

In the end Go was mainly chosen to be evaluated further because of promised ``simple'' parallelism via goroutines. It will probably not directly compete with C in execution performance but the great toolchain and simplified concurrency might outshine the performance loss.

%- Prediction implementation
%    - A bit of syntax weirdness
%    - Relatively quick PoC with decent concurrency aspects
%    - Some fixing/optimization afterwards regarding common concurrency errors
%    -> More time spent after initial PoC but less than in C


\subsection*{Rust}
\label{subsec:State_of_the_art::Candidates::Rust}

The last candidate discussed in this chapter is Rust. Developed in the open but strongly backed by Mozilla Rust aims to directly compete with C and C++ as a systems language. It focuses on memory safety which is checked and verified at compile without (or with minimal) impact on runtime performance. Rust compiles to native code using a custom fork of the popular LLVM\fnote{\url{http://www.llvm.org}} as backend and is compatible to common tools like \textbf{The GNU Project Debugger} (\textit{gdb})\fnote{\url{http://www.gnu.org/software/gdb/}} which makes integration into existing workflows a bit easier.

Out of the here discussed languages Rust is closest to C while attempting to fix common mistakes made possible by it's loose standard allowing undefined behaviour. (//wording?) Memory safety is enforced through a very sophisticated model of ownership. It is based on common concepts which are already employed on concurrent applications but integrates them on a langage level and enforces them at compile time. The basic rule is that every resource in an applications (for example allocated memory or file handles) has exactly one \textit{owner} at a time. To share access to a resource one can you use references denoted by a \mdinline{\&}. These can been seen as pointers in C with the additional caveat that they are readonly. To gain mutable access to a resource one must acquire a mutable reference via \mdinline{\&mut}. To ensure memory safety a special part of the compiler, the \textit{borrow checker}, validates that there is never more than one mutable reference to the same resource. This effectively prevents mutable aliasing which in turn rules out a whole class of errors like iterator invalidation. It is important to remember that these checks are a ``zero cost abstraction'' which means they do not have any runtime overhead but enforce additional security at compile time through static analysis.

Another core aspect of Rust are \textit{lifetimes}. As many other programming languages Rust has scopes introduced by blocks for example function and loop bodies or arbitrary scopes opened and closed by curly braces. Combined with the ownership system the compiler can exactly determine when the owner of a resource gets out of scope and call the appropiate destructor (called \mdinline{drop} in Rust). This technique is called ``Resource acquisition is initialization''~\cite[p. 389]{evolution_c++}. Unlike in C++ it is not limited to stack allocated objects since the compiler can rely on the ownership system to verify that no references to a resource are left when its owner gets out of scope. It is therefore safe to drop. //wording
\\
\lstinputlisting[caption={Rust example}, lable={lst:example.rs}, style=rust]{code/example.rs}

Although Rust focusses on performance and safety it also adopted some functional concepts like \textit{pattern matching} and the \mdinline{Option} type. Combined with \mdinline{range} expressions and macros which operate on syntax level coding in Rust often feels like in a scripting language which is just very performant. This was also the main reason it was chosen to be further evaluated. Rust focusses on safety while not sacrificing any performnce in the process. Most of the checks happen at compile time making the resulting binary often close or on par with equivalent C programs. It also has the advantage of beeing still in development\fnote{current version beeing \textsc{1.0.0-alpha-2} at the time of this writing} so concepts which did not work out can be quickly changed or completely dropped.
But Rust's immatureness is also its greatest weakness. The

% - mention cargo
%
% - Prediction Implementation
%     - Moderatly quick PoC without concurrency at first
%     - Nearly only otimization afterwards since compilation secures memory safety
%     -> More time spent before initial PoC than after


\subsection*{Comparison}
\label{subsec:State_of_the_art::Candidates::Comparison}

% will probably not fit
\begin{tabular}{llll}
    \toprule
    % Header
        & Python
        & Erlang
        & Go
        & Rust \\
    \midrule

    Execution model
        & interpreted
        & compiled to bytecode
        & compiled to native code
        & compiled to native code \\

    Advantagesree) concurrency support
        & adv go
        & adv rust \\

    Disadvantages
        & speed
        & obscure syntax
        & mandatory runtime
        & disadv rust \\

    Relative speed
        & slow to average
        & average to fast
        & speed go
        & speed rust \\
    \bottomrule
\end{tabular}

\section{Related work}
\label{sec:Introduction::Related}

The search for new programming languages which are fit for \gls{hpc} is not a recently developing trend. There have been multiple studies and evaluations but so far none of the proposed languages have gained enough traction to receive widespread adoption. Also most reports focused on the execution performance without really considering additional software metrics or developer productivity. \cite{related_multicore} at least adds lines of code and development time to the equation but both of these metrics only allow for superficial conclusions about the code quality.

From the here presented candidates Go in particular has been compared to other approaches to parallel programming with mixed results. Although its regular execution speed is somewhat lacking \cite{related_sor_study} showed the highest speedup from parallelization amongst the evaluated languages.

// needs more work

// really mention this here without \refs?
Rust on the other hand has not been seriously evaluated in the HPC environment mostly due to its 
