\chapter{State of the art}
\label{ch:State_of_the_art}

\abstract{%
This chapter describes the current state of the art in high-performance computing. The dominance of Fortran and C is explained and questioned. After that all considered language candidates are introduced and characterized.
}

\section{Programming Paradigms in Fortran and C}
\label{sec:State_of_the_art::Paradigms}

As stated in~\autoref{sec:Introduction::Motivation}, high-performance computing is largely dominated by C and Fortran and although their trademark is mostly performance these two languages achieve this in very different ways. Unfortunately both approaches are not completely satisfying and could be improved.

Fortran (originally an acronym for FORmula TRANslation) is the traditional choice for scientific applications like climate simulations. As the name suggests it was originally developed to allow for easy computation of mathematical formulae on computers. In spite of Fortran being one of the oldest programming languages it is actually fairly high-level. It provides \gls{intrinsic} functions for many common mathematical operations such as matrix multiplication or trigonometric functions and a built-in datatype for complex numbers. In addition, memory management is nearly nonexistent. In earlier versions of Fortran it was not possible to explicitly allocate data. Even in programs written in newer revisions of the language, allocation and memory sharing often only account for a small fraction of the source code.

While this high-level paradigm of scientific programming is certainly well suited for a lot of applications, especially for scientists with mathematical backgrounds, it can also be insufficient in some edge cases. Notably in performance critical sections the \gls{intrinsic} functions sometimes are just not fast enough and the programmer has to fall back to manual solutions or external libraries. Because Fortran does not offer fine grained control over memory or other resources some algorithms cannot be fully optimized which can limit performance. Of course this is not the general case and normally the compiler can generate efficient code but in machine dependent regions like caches or \gls{loop_unrolling} Fortran simply does not give the programmer enough control to finetune every last bit.

C on the other hand approaches performance totally differently. Developed as a general purpose language it provides the tools to build efficient mathematical functions and datatypes which in turn require a lot more micromanagement than their equivalents in Fortran. This allows the programmer to carefully tweak each operation to achieve maximum performance at the cost of high-level abstractions. Thus C is often the language of choice for computer scientists when performance is the main concern but it is rather ill-suited for people without broad knowledge about memory and other machine internals.

The main drawback of both languages is their age. Even though new revisions are regularly accepted Fortran and C strive to be backwards compatible for the most part. This has some very serious consequences especially in their respective syntaxes. A lot of features of newer standards are integrated suboptimally to preserve backwards compatibility. Newer languages can take advantage of all past research without having to adhere to outdated idioms and patterns.

\section{Language Candidates}
\label{sec:State_of_the_art::Candidates}

As previously stated, Go and Rust were chosen to be evaluated in the context of \gls{hpc}. This section aims to provide a rough overview of all language candidates that were considered for further evaluation in this thesis.

\subsection*{Python}
\label{subsec:State_of_the_art::Candidates::Python}

Python is an interpreted general-purpose programming language which aims to be very expressive and flexible. Compared with C and Fortran which sacrifice feature richness for performance, Python's huge standard library combined with the automatic memory management offers a low border of entry and quick prototyping capabilities.

As a matter of fact many introductory computer science courses at universities in the United States recently switched from Java to Python as their first programming language~\cite{GUO14, intro_py}. This allows the students to focus on core concepts of coding and algorithms instead of distracting boilerplate code. \autoref{lst:example.py} demonstrates just a few of Python's core features which make it a great first programming language to learn.
\\
\lstinputlisting[caption={FizzBuzz in Python 3.4}, label={lst:example.py}, style=python]{code/example.py}

In addition to the very extensive standard library the Python community has created a lot of open source projects aiming to support especially scientific applications. There is NumPy\fnote{\url{http://www.numpy.org}} which offers efficient implementations for multidimensional arrays and common numeric algorithms like Fourier transforms or MPI4Py\fnote{\url{http://www.mpi4py.scipy.org}}, an \gls{mpi} abstraction layer able to interface with various backends like OpenMPI or MPICH. Especially the existence of the latter shows the ongoing attempts to use Python in a cluster environment and there have been successful examples of scientific high performance applications using these libraries as seen in~\cite{pyfr}.

Unfortunately dynamic typing and automatic memory management come at a rather high price. The speed of raw numeric algorithms written in plain Python is almost always orders of magnitude slower than implementations in C or Fortran. As a consequence, nearly all of the mentioned libraries implement the critical routines in C. This often means one needs to make tradeoffs between idiomatic Python - which might not be transferable to the foreign language - and maximum performance. As a result, performance critical Python code often looks like its equivalent written in a statically typed language.

In conclusion Python was not chosen to be further evaluated because of the mentioned lack of performance (in pure Python). This might change with some new implementations emerging recently though. Most of the problems discussed here are present in all stable Python implementations today (most notably \textit{CPython}\fnote{\url{https://www.python.org}} and \textit{PyPy}\fnote{\url{http://www.pypy.org}}) but new projects aim to improve the execution speed in various ways. \textit{Medusa}\fnote{\url{https://github.com/rahul080327/medusa}} compiles Python code to Google's \textit{Dart}\fnote{\url{https://www.dartlang.org/}} to make use of the underlying virtual machine. Although these ventures are still in early phases of development, first early benchmarks promise drastic performance improvements. Once Python can achieve similar execution speed to native code it will become a serious competitor in the \gls{hpc} area.

\subsection*{Erlang}
\label{subsec:State_of_the_art::Candidates::Erlang}

Erlang is a specific purpose programming language originally designed for the use in telephony applications. It features a high focus on concurrency and a garbage collector which is enabled through the execution inside the \gls{beam} virtual machine. Today it is most often used in soft real-time computing\fnote{see \url{https://en.wikipedia.org/wiki/Real-time_computing}} because of its error tolerance, hot code reload capabilities and lock-free concurrency support~\cite{intro_erlang}.

Erlang has a very unique and specialized syntax which is very different from C-like languages. It abstains from using any kind of parentheses as block delimiters and instead uses a mix of periods, semicolons, commas and arrows (\mdinline{->}). Unfortunately the rules for applying these symbols are not very intuitive and may even seem random for newcomers at times.

One core concept of Erlang is the idea of processes. These lightweight primitives of the language are provided by the virtual machine and are neither direct mappings of operating system threads nor processes. One the one hand they are cheap to create and destruct (like threads) but do not share any address space or other state (like processes). Because of this, the only way to communicate is through message passing which can be handled via the \mdinline{receive} keyword and sent via the \mdinline{!} operator~\cite{erlang_phd, intro_erlang}.
\\
\lstinputlisting[caption={Erlang example}, label={lst:example.erl}, style=erlang]{code/example.erl}

\autoref{lst:example.erl} illustrates some of these key features like code reloading and message passing. Further mode Erlang offers various constructs known from functional languages like pattern matching, clause based function definition and immutable variables but the language as a whole is not purely functional. Each Erlang process in itself behaves purely (meaning the result of a function depends solely on its input). The collection of processes interacting with each other through messages contain state and side effects.

Erlang was considered as a possible candidate for \gls{hpc} because of its concurrency capabilities. The fact that processes are a core part of the language and are rather cheap in both creation and destruction seems ideal for high performance applications often demanding enormous amounts of parallelism. Sadly Erlang suffers from what one might call over specialization. The well adapted type system makes it very suited for tasks where concurrency is essential like serverside request management, task scheduling and other services with high connection fluctuation, but ``The ease of concurrency doesnâ€™t make up for the difficulty in interfacing with other languages''~\cite{erlang_fps}. Even advocates of Erlang say they would not use it for regular business logic. In \gls{hpc},  most of the processing time is spent solving numeric problems. These are of course parallelized to increase effectiveness but the concurrency aspect is often not really inherent to the problem itself. Because of this Erlang's concurrency capabilities just do not outweigh its numeric slowness for traditional \gls{hpc} problems~\cite{erlang_guide}.

\subsection*{Go}
\label{subsec:State_of_the_art::Candidates::Go}

Go is a relatively young programming language which focuses on simplicity and clarity while not sacrificing too much performance. Initially developed by Google it aims to ``make it easy to build simple, reliable and efficient software''~\cite{go_home}. It is statically typed, offers a garbage collector, basic type inference and a large standard library. Go's syntax is loosely inspired by C but made some major changes like removing the mandatory semicolon at the end of commands and changing the order of types and identifiers. It was chosen as a candidate because it provides simple concurrency primitives as part of the language (so called \textit{\glspl{goroutine}}) while having a familiar syntax and reaching reasone performance~\cite{intro_go}. It also compiles to native code without external dependencies which makes it usable on cluster computers without many additional libraries installed.

\autoref{lst:example.go} demonstrates two key features which are essential to concurrent programming in Go - the already mentioned \glspl{goroutine} as well as channels which are used for synchronization purposes. They provide a way to communicate with running \glspl{goroutine} via message passing. The \hyperref[lst:example.go]{Listing} below features a simple example writing multiple messages concurrently and using these channels to prevent premature exit of the parent thread.
\newpage
\lstinputlisting[caption={Go concurrency example}, label={lst:example.go}, style=go]{code/example.go}

Initially developed for server scenarios Go has seen production use in many different areas. At Google it is used for various internal project such as the download service ``dl.google.com'' which has been completely rewritten from C++ to Go in 2012. The new version can handle more bandwith while using less memory. It is also noteable that the Go codebase is about half the size of the legacy application with increased test coverage and performance~\cite{go_dl_google}.

While Go's focus on simplicity is admireable it has also been its greatest point of criticism. The language feature set is very carefully selected and rarely extended. It even misses some of the most natural constructs which a programmer might expect in a reasonably high-level language - the main example for this being generics. At the time of this writing Go does not offer the common concept of generic types or functions and the authors have stated this is not a big priority at the moment.

One other important fact - especially for high-performance computing - is the mandatory garbage collector. Go completey takes the burden of memory management out of the hands of the programmer and relies on the embedded runtime to efficiently perform this job. This makes it impossible to predictably allocate and release memory which can lead to performance loss. This also means the Go runtime has to be linked into every application. To prevent additional dependencies on target machines the language designers chose to link all libraries statically including the runtime. Although that might not be important for bigger codebases it increases the binary size considerably.

In the end, Go was mainly chosen to be evaluated further because it provides easy to use parallel constructs, the aforementioned \glspl{goroutine}. It will probably not directly compete with C in execution performance but the great toolchain and simplified concurrency might top the performance loss.

\subsection*{Rust}
\label{subsec:State_of_the_art::Candidates::Rust}

The last candidate discussed in this chapter is Rust. Developed in the open but strongly backed by Mozilla Rust aims to directly compete with C and C++ as a systems language. It focuses on memory safety which is checked and verified at compile without (or with minimal) impact on runtime performance. Rust compiles to native code using a custom fork of the popular \textit{LLVM}\fnote{\url{http://www.llvm.org}} as backend and is compatible to common tools like \textit{The GNU Project Debugger} (\textit{gdb})\fnote{\url{http://www.gnu.org/software/gdb/}} which makes integration into existing workflows a bit easier. Compared to the languages discussed here in this chapter Rust is closest to C while attempting to fix common mistakes made possible by its loose standard allowing undefined behavior.

\textbf{Memory safety} is enforced through a very sophisticated model of ownership tracking. It is based on common concepts which are already employed on concurrent applications but integrates them on a language level and enforces them at compile time. The basic rule is that every resource in an application (for example allocated memory or file handles) has exactly one \textit{owner} at a time. To \textbf{share access} to a resource one can you use references denoted by a \shinline{\&}. These can been seen as pointers in C with the additional constraint that they are readonly. To gain \textbf{mutable access} to a resource one must acquire a mutable reference via \shinline{\&mut}. To ensure memory safety a special part of the compiler, the \textit{borrow checker}, validates that there is never more than one mutable reference to the same resource. This effectively prevents \textbf{mutable aliasing} which in turn rules out a whole class of errors like \textit{\gls{iterator_invalidation}}. It is important to remember that these checks are a \textbf{``zero cost abstraction''} which means they have zero or minimal runtime overhead while enforcing additional security at compile time through static analysis.

Another core aspect of Rust are \textbf{lifetimes}. As many other programming languages Rust has scopes introduced by blocks such as function and loop bodies or arbitrary scopes opened and closed by curly braces. Combined with the ownership system the compiler can exactly determine when the owner of a resource gets out of scope and call the appropiate destructor (called \shinline{drop} in Rust). This technique is called ``Resource acquisition is initialization''~\cite[p. 389]{evolution_c++}. Unlike in C++ it is not limited to stack allocated objects since the compiler can rely on the ownership system to verify that no references to a resource are left when its owner gets out of scope. It is therefore safe to drop and can be safely freed.
\\
\lstinputlisting[caption={Rust example}, label={lst:example.rs}, style=rust]{code/example.rs}

Although Rust focuses on performance and safety it also adopted some functional concepts like \textit{pattern matching} and the \textbf{Option} type as demonstrated in \autoref{lst:example.rs}. Combined with \textbf{range} expressions and macros which operate on syntax level coding in Rust often feels like in a scripting language which is just very performant. This was also the main reason it was chosen to be further evaluated. Rust targets safety without sacrificing any performnce in the process. Most of the checks happen at compile time making the resulting binary often nearly identical to an equivalent C program. It also has the advantage of being still in development\fnote{The current version is \shinline{1.0.0-beta.2} at the time of this writing} so concepts which did not work out can be quickly changed or completely dropped.

But the immatureness of Rust is also its greatest weakness. The language is still changing every day which means code written today might not compile tomorrow. However the breaking changes are getting less as the first stable release is scheduled to be issued on 2015-05-15. Rust 1.0.0 is guaranteed to be backwards compatible for all later versions so the language should soon be ready for production use. Meanwhile the toolchain is already quite impressive. In addition to the compiler the default installation also contains a package manager called \shinline{cargo}. It is able to fetch dependencies from git repositories or the central package repository located on \url{https://crates.io} and can build complex projects including linking to native C libraries. It is obviously still in development but the feature set is already very broad.

Rust was chosen to be evaluated further because it should be able to match C's execution speed while providing additional \textbf{memory safety} and modern language features. Even if the \textbf{performance} is not completely similar to native code the \textbf{productivity gains} should still be substantial.
